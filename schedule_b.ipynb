{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapidly Prototyping a Machine Learning Pipeline\n",
    "\n",
    "The purpose of this workshop is to show how easy it is to take an idea and turn it into a successful Machine Learning application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 0\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# this is a trick to parallelize our computations\n",
    "import multiprocessing\n",
    "NCPUS = 8 if multiprocessing.cpu_count() > 8 else (multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will (ideally) install NLTK\n",
    "# and download the english stopwords.\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: The idea/loading data\n",
    "In line with Tuesday's panel around \"autocoders,\" we'll demonstrate how to use text descriptions to predict codes. Along the way, we'll show some good practice when practicing machine learning. While this notebook will focus on coding products using descriptions, this approach should work for many scenarios where one has a dataset with both text descriptions and their associated codes.\n",
    "\n",
    "#### The data\n",
    "This data comes from Census' own Foreign Trade site: https://www.census.gov/foreign-trade/schedules/b/index.html#download\n",
    "\n",
    "Specifically, this is the \"concordance file\" for the Harmonized System's import/export codes. This gives us the code and a description of what products fit into that code: perfect for the sort of automatic coding we want to do. We've included the file here (in the `data/` subfolder) for ease-of-use.\n",
    "\n",
    "The import and export codes are slightly different at the 10-digit level; however, the codes are heirarchical and at the 6-digit level they are the same (as defined by an international standards group). We'll model at an even less granular level than that - the 4-digit level - based on the amount of data that we have.\n",
    "\n",
    "First, let's take a look in a text editor. Jupyter has one that's enough for this.\n",
    "\n",
    "From here, taking a look at the `imp-stru.txt` file will give us the \"schema.\"\n",
    "\n",
    "Now, we'll use a combination of python and pandas to ingest and clean this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we develop this by looking at the 'imp-stru.txt' file. the export structure is also the same\n",
    "def process_impexp_line(line, which='import'):\n",
    "    hs_code = line[:10]\n",
    "    short_desc = line[14:65]\n",
    "    long_desc = line[69:219]\n",
    "    return (hs_code, short_desc, long_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0101210010',\n",
       "  'HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE    ',\n",
       "  'HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE                                                                                                       '),\n",
       " ('0101210020',\n",
       "  'HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE  ',\n",
       "  'HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE                                                                                                     '),\n",
       " ('0101290010',\n",
       "  'HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI       ',\n",
       "  'HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING                                                                              ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is one way of reading / processing a file in python\n",
    "with open(\"data/imp-code.txt\") as imp_f:\n",
    "    imp_lines = []\n",
    "    for line in imp_f:\n",
    "        imp_lines.append(process_impexp_line(line))\n",
    "        \n",
    "# let's take a look. Note all the extra whitespace. We'll have to remove that.\n",
    "imp_lines[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0101210000',\n",
       "  'HORSES, PUREBRED BREEDING, LIVE                    ',\n",
       "  'HORSES, PUREBRED BREEDING, LIVE                                                                                                                       '),\n",
       " ('0101290000',\n",
       "  'HORSES, LIVE, EXCEPT PUREBRED BREEDING             ',\n",
       "  'HORSES, LIVE, EXCEPT PUREBRED BREEDING                                                                                                                '),\n",
       " ('0101300000',\n",
       "  'ASSES, LIVE                                        ',\n",
       "  'ASSES, LIVE                                                                                                                                           ')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a slightly fancier way of doing the same thing\n",
    "with open(\"data/exp-code.txt\") as exp_f:\n",
    "    exp_lines = [process_impexp_line(line) for line in exp_f]\n",
    "        \n",
    "# always good to take a look at things along the way\n",
    "exp_lines[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got two lists (`imp_lines` and `exp_lines`) that hold all of the codes and descriptions, let's put them in a data frame and start processing/looking around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = imp_lines + exp_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101210010</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101210020</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                    1  \\\n",
       "0  0101210010  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE       \n",
       "1  0101210020  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE     \n",
       "\n",
       "                                                                                                                                                        2  \n",
       "0  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE                                                                                                         \n",
       "1  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE                                                                                                       "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see in the output, pandas is smart enough to take a list of tuples\n",
    "# and turn it into a table in a \"sensible\" way. We do need to specify column names though.\n",
    "df = pd.DataFrame(all_lines)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df has 28469 rows\n",
      "df has 22660 unique HS 10-digit codes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS10</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>long_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101210010</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101210020</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101290010</td>\n",
       "      <td>HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI</td>\n",
       "      <td>HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101290090</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101300000</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HS10                                           short_desc  \\\n",
       "0  0101210010  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE       \n",
       "1  0101210020  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE     \n",
       "2  0101290010  HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI          \n",
       "3  0101290090  HORSES, LIVE, NESOI                                   \n",
       "4  0101300000  ASSES, LIVE                                           \n",
       "\n",
       "                                                                                                                                                long_desc  \n",
       "0  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE                                                                                                         \n",
       "1  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE                                                                                                       \n",
       "2  HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING                                                                                \n",
       "3  HORSES, LIVE, NESOI                                                                                                                                     \n",
       "4  ASSES, LIVE                                                                                                                                             "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_lines, columns=['HS10', 'short_desc', 'long_desc'])\n",
    "print(\"df has\", len(df), \"rows\")\n",
    "print(\"df has\", df['HS10'].nunique(), 'unique HS 10-digit codes')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. We have something like 28,000 rows. As we can immediately see, there is some overlap between the 10-digit import and export codes, hence the only ~22,000 unique 10-digit codes. It is likely that duplicate codes have the same description in both files... and from the perspective of the model, 2 copies of the same description/code is just as good as 1, so we'll only want to retain one copy of those. Additionally, we need to standardize and process this text, which will probably leave us with more of duplicate text strings as well. Let's start processing and find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Cleaning / processing the data\n",
    "\n",
    "There are two main libraries for cleaning and processing text data in Python:\n",
    "- `spaCy`\n",
    "- `nltk`\n",
    "In this case, we'll use nltk, but spaCy is equally as good.\n",
    "\n",
    "Additionally, depending on the type of text that you have, there are many different ways to process and \"extract features\" (i.e. create variables for modelling) from that text. For example, if you're working with phrases/sentences, spaCy has good tools for determining which part-of-speech each word in a sentence maps to.\n",
    "\n",
    "In our case, we have very simple product descriptions (perhaps closer to \"tags\" than sentences), so less processing is required. We'll start out by using regular expressions. This is a good tutorial to learn more about those: https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS10</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>long_stripped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>2508700000</td>\n",
       "      <td>CHAMOTTE OR DINAS EARTH</td>\n",
       "      <td>CHAMOTTE OR DINAS EARTH</td>\n",
       "      <td>CHAMOTTE OR DINAS EARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>6001920040</td>\n",
       "      <td>OTHER PILE FABRIC MMF OTH LT 271 G/M2 KNIT/CROCHET</td>\n",
       "      <td>OTHER PILE FABRIC, OF MAN-MADE FIBERS, KNITTED OR CROCHETED, NOT OVER 271 G/M2, NOT VELOUR</td>\n",
       "      <td>OTHER PILE FABRIC, OF MAN-MADE FIBERS, KNITTED OR CROCHETED, NOT OVER 271 G/M2, NOT VELOUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16052</th>\n",
       "      <td>8481809020</td>\n",
       "      <td>ELECTRICAL ACTUATOR, NESOI,OPERT BY SIG. FM CNTL</td>\n",
       "      <td>ELECTRICAL OR ELECTRO-HYDRAULIC ACTUATORS WITH CONTROL VALVES DESIGNED FOR PROPORTIONAL OPERATION BY A SIGNAL FROM A CONTROL DEVICE</td>\n",
       "      <td>ELECTRICAL OR ELECTRO-HYDRAULIC ACTUATORS WITH CONTROL VALVES DESIGNED FOR PROPORTIONAL OPERATION BY A SIGNAL FROM A CONTROL DEVICE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             HS10                                           short_desc  \\\n",
       "3278   2508700000  CHAMOTTE OR DINAS EARTH                               \n",
       "9329   6001920040  OTHER PILE FABRIC MMF OTH LT 271 G/M2 KNIT/CROCHET    \n",
       "16052  8481809020  ELECTRICAL ACTUATOR, NESOI,OPERT BY SIG. FM CNTL      \n",
       "\n",
       "                                                                                                                                                    long_desc  \\\n",
       "3278   CHAMOTTE OR DINAS EARTH                                                                                                                                  \n",
       "9329   OTHER PILE FABRIC, OF MAN-MADE FIBERS, KNITTED OR CROCHETED, NOT OVER 271 G/M2, NOT VELOUR                                                               \n",
       "16052  ELECTRICAL OR ELECTRO-HYDRAULIC ACTUATORS WITH CONTROL VALVES DESIGNED FOR PROPORTIONAL OPERATION BY A SIGNAL FROM A CONTROL DEVICE                      \n",
       "\n",
       "                                                                                                                             long_stripped  \n",
       "3278   CHAMOTTE OR DINAS EARTH                                                                                                              \n",
       "9329   OTHER PILE FABRIC, OF MAN-MADE FIBERS, KNITTED OR CROCHETED, NOT OVER 271 G/M2, NOT VELOUR                                           \n",
       "16052  ELECTRICAL OR ELECTRO-HYDRAULIC ACTUATORS WITH CONTROL VALVES DESIGNED FOR PROPORTIONAL OPERATION BY A SIGNAL FROM A CONTROL DEVICE  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll do this step-by-step, to illustrate\n",
    "df['long_stripped'] = df['long_desc'].str.strip()\n",
    "\n",
    "# this is pulling 5 random rows, instead of the top 5, just for some variety\n",
    "# note the new colummn\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS10</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>long_stripped</th>\n",
       "      <th>long_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101210010</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>horses and asses, purebred breeding, male, live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101210020</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>horses and asses, purebred breeding, female, live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HS10                                           short_desc  \\\n",
       "0  0101210010  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE       \n",
       "1  0101210020  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE     \n",
       "\n",
       "                                                                                                                                                long_desc  \\\n",
       "0  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE                                                                                                          \n",
       "1  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE                                                                                                        \n",
       "\n",
       "                                       long_stripped  \\\n",
       "0  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE     \n",
       "1  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE   \n",
       "\n",
       "                                          long_lower  \n",
       "0  horses and asses, purebred breeding, male, live    \n",
       "1  horses and asses, purebred breeding, female, live  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['long_lower'] = df['long_stripped'].str.lower()\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS10</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>long_stripped</th>\n",
       "      <th>long_lower</th>\n",
       "      <th>long_word_list</th>\n",
       "      <th>long_words_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101210010</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>horses and asses, purebred breeding, male, live</td>\n",
       "      <td>[horses, and, asses, purebred, breeding, male, live]</td>\n",
       "      <td>horses and asses purebred breeding male live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101210020</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>horses and asses, purebred breeding, female, live</td>\n",
       "      <td>[horses, and, asses, purebred, breeding, female, live]</td>\n",
       "      <td>horses and asses purebred breeding female live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101290010</td>\n",
       "      <td>HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI</td>\n",
       "      <td>HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING</td>\n",
       "      <td>HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING</td>\n",
       "      <td>horses, imported for immediate slaughter, live, except purebred breeding</td>\n",
       "      <td>[horses, imported, for, immediate, slaughter, live, except, purebred, breeding]</td>\n",
       "      <td>horses imported for immediate slaughter live except purebred breeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101290090</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "      <td>horses, live, nesoi</td>\n",
       "      <td>[horses, live, nesoi]</td>\n",
       "      <td>horses live nesoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101300000</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "      <td>asses, live</td>\n",
       "      <td>[asses, live]</td>\n",
       "      <td>asses live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HS10                                           short_desc  \\\n",
       "0  0101210010  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE       \n",
       "1  0101210020  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE     \n",
       "2  0101290010  HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI          \n",
       "3  0101290090  HORSES, LIVE, NESOI                                   \n",
       "4  0101300000  ASSES, LIVE                                           \n",
       "\n",
       "                                                                                                                                                long_desc  \\\n",
       "0  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE                                                                                                          \n",
       "1  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE                                                                                                        \n",
       "2  HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING                                                                                 \n",
       "3  HORSES, LIVE, NESOI                                                                                                                                      \n",
       "4  ASSES, LIVE                                                                                                                                              \n",
       "\n",
       "                                                              long_stripped  \\\n",
       "0  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE                            \n",
       "1  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE                          \n",
       "2  HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING   \n",
       "3  HORSES, LIVE, NESOI                                                        \n",
       "4  ASSES, LIVE                                                                \n",
       "\n",
       "                                                                 long_lower  \\\n",
       "0  horses and asses, purebred breeding, male, live                            \n",
       "1  horses and asses, purebred breeding, female, live                          \n",
       "2  horses, imported for immediate slaughter, live, except purebred breeding   \n",
       "3  horses, live, nesoi                                                        \n",
       "4  asses, live                                                                \n",
       "\n",
       "                                                                    long_word_list  \\\n",
       "0  [horses, and, asses, purebred, breeding, male, live]                              \n",
       "1  [horses, and, asses, purebred, breeding, female, live]                            \n",
       "2  [horses, imported, for, immediate, slaughter, live, except, purebred, breeding]   \n",
       "3  [horses, live, nesoi]                                                             \n",
       "4  [asses, live]                                                                     \n",
       "\n",
       "                                                         long_words_only  \n",
       "0  horses and asses purebred breeding male live                           \n",
       "1  horses and asses purebred breeding female live                         \n",
       "2  horses imported for immediate slaughter live except purebred breeding  \n",
       "3  horses live nesoi                                                      \n",
       "4  asses live                                                             "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# this is in general one of the more useful regular expressions to know\n",
    "# the '\\w' searches for word-like tokens, and the '+' says \"one or more\"\n",
    "# combined, this gets us 'one or more characters', i.e. word tokens w/o commas, spaces, etc.\n",
    "WORD_REGEX = r'\\w+'\n",
    "\n",
    "def find_words(desc):\n",
    "    return re.findall(WORD_REGEX, desc)\n",
    "df['long_word_list'] = df['long_lower'].apply(find_words)\n",
    "df['long_words_only'] = df['long_word_list'].str.join(' ')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean things up a bit, let's get rid of some of these intermediate columns.\n",
    "\n",
    "In practice, this is a useful thing to do because it will free up memory. If you find your code is using too much memory or is running very slow, then consider deleting unnecessary columns in this manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS10</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>long_words_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101210010</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>horses and asses purebred breeding male live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101210020</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>horses and asses purebred breeding female live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101290010</td>\n",
       "      <td>HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI</td>\n",
       "      <td>HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING</td>\n",
       "      <td>horses imported for immediate slaughter live except purebred breeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101290090</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "      <td>horses live nesoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101300000</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "      <td>asses live</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HS10                                           short_desc  \\\n",
       "0  0101210010  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE       \n",
       "1  0101210020  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE     \n",
       "2  0101290010  HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI          \n",
       "3  0101290090  HORSES, LIVE, NESOI                                   \n",
       "4  0101300000  ASSES, LIVE                                           \n",
       "\n",
       "                                                                                                                                                long_desc  \\\n",
       "0  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE                                                                                                          \n",
       "1  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE                                                                                                        \n",
       "2  HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING                                                                                 \n",
       "3  HORSES, LIVE, NESOI                                                                                                                                      \n",
       "4  ASSES, LIVE                                                                                                                                              \n",
       "\n",
       "                                                         long_words_only  \n",
       "0  horses and asses purebred breeding male live                           \n",
       "1  horses and asses purebred breeding female live                         \n",
       "2  horses imported for immediate slaughter live except purebred breeding  \n",
       "3  horses live nesoi                                                      \n",
       "4  asses live                                                             "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running this cell more than once will cause an error\n",
    "# because when you try to delete somethat that has \n",
    "# already been deleted, it's no longer there\n",
    "del df['long_stripped']\n",
    "del df['long_lower']\n",
    "del df['long_word_list']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Initial Model\n",
    "Now that we've gotten English words only, we can try a simple model. Let's get into the modelling approach and the package that we'll use to implement it, `scikit-learn`.\n",
    "\n",
    "#We'll be implementing a _bag-of-words_ model. The idea is very simple: each word becomes a separate variable. For each variable, the value is the number of times that word occurs in that particular record. Let's demonstrate with a quick example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    horses and asses purebred breeding male live                         \n",
       "1    horses and asses purebred breeding female live                       \n",
       "2    horses imported for immediate slaughter live except purebred breeding\n",
       "3    horses live nesoi                                                    \n",
       "4    asses live                                                           \n",
       "Name: long_words_only, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try this process on the first few and see what we get back\n",
    "first_few_only = df.head()\n",
    "# look at the final results, for reference\n",
    "first_few_only['long_words_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit-learn calls this process \"vectorizing\", i.e. turning a sentence into a vector of variables.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "# this will actually convert our first few descriptions into vectors\n",
    "tfd = cv.fit_transform(first_few_only['long_words_only'])\n",
    "# by default, it's a sparse matrix\n",
    "tfd.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For explainability, let's cleanly present this mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>asses</th>\n",
       "      <th>breeding</th>\n",
       "      <th>except</th>\n",
       "      <th>female</th>\n",
       "      <th>for</th>\n",
       "      <th>horses</th>\n",
       "      <th>immediate</th>\n",
       "      <th>imported</th>\n",
       "      <th>live</th>\n",
       "      <th>male</th>\n",
       "      <th>nesoi</th>\n",
       "      <th>purebred</th>\n",
       "      <th>slaughter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_words_only</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>horses and asses purebred breeding male live</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horses and asses purebred breeding female live</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horses imported for immediate slaughter live except purebred breeding</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horses live nesoi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asses live</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       and  \\\n",
       "long_words_only                                                              \n",
       "horses and asses purebred breeding male live                           1     \n",
       "horses and asses purebred breeding female live                         1     \n",
       "horses imported for immediate slaughter live except purebred breeding  0     \n",
       "horses live nesoi                                                      0     \n",
       "asses live                                                             0     \n",
       "\n",
       "                                                                       asses  \\\n",
       "long_words_only                                                                \n",
       "horses and asses purebred breeding male live                           1       \n",
       "horses and asses purebred breeding female live                         1       \n",
       "horses imported for immediate slaughter live except purebred breeding  0       \n",
       "horses live nesoi                                                      0       \n",
       "asses live                                                             1       \n",
       "\n",
       "                                                                       breeding  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           1          \n",
       "horses and asses purebred breeding female live                         1          \n",
       "horses imported for immediate slaughter live except purebred breeding  1          \n",
       "horses live nesoi                                                      0          \n",
       "asses live                                                             0          \n",
       "\n",
       "                                                                       except  \\\n",
       "long_words_only                                                                 \n",
       "horses and asses purebred breeding male live                           0        \n",
       "horses and asses purebred breeding female live                         0        \n",
       "horses imported for immediate slaughter live except purebred breeding  1        \n",
       "horses live nesoi                                                      0        \n",
       "asses live                                                             0        \n",
       "\n",
       "                                                                       female  \\\n",
       "long_words_only                                                                 \n",
       "horses and asses purebred breeding male live                           0        \n",
       "horses and asses purebred breeding female live                         1        \n",
       "horses imported for immediate slaughter live except purebred breeding  0        \n",
       "horses live nesoi                                                      0        \n",
       "asses live                                                             0        \n",
       "\n",
       "                                                                       for  \\\n",
       "long_words_only                                                              \n",
       "horses and asses purebred breeding male live                           0     \n",
       "horses and asses purebred breeding female live                         0     \n",
       "horses imported for immediate slaughter live except purebred breeding  1     \n",
       "horses live nesoi                                                      0     \n",
       "asses live                                                             0     \n",
       "\n",
       "                                                                       horses  \\\n",
       "long_words_only                                                                 \n",
       "horses and asses purebred breeding male live                           1        \n",
       "horses and asses purebred breeding female live                         1        \n",
       "horses imported for immediate slaughter live except purebred breeding  1        \n",
       "horses live nesoi                                                      1        \n",
       "asses live                                                             0        \n",
       "\n",
       "                                                                       immediate  \\\n",
       "long_words_only                                                                    \n",
       "horses and asses purebred breeding male live                           0           \n",
       "horses and asses purebred breeding female live                         0           \n",
       "horses imported for immediate slaughter live except purebred breeding  1           \n",
       "horses live nesoi                                                      0           \n",
       "asses live                                                             0           \n",
       "\n",
       "                                                                       imported  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0          \n",
       "horses and asses purebred breeding female live                         0          \n",
       "horses imported for immediate slaughter live except purebred breeding  1          \n",
       "horses live nesoi                                                      0          \n",
       "asses live                                                             0          \n",
       "\n",
       "                                                                       live  \\\n",
       "long_words_only                                                               \n",
       "horses and asses purebred breeding male live                           1      \n",
       "horses and asses purebred breeding female live                         1      \n",
       "horses imported for immediate slaughter live except purebred breeding  1      \n",
       "horses live nesoi                                                      1      \n",
       "asses live                                                             1      \n",
       "\n",
       "                                                                       male  \\\n",
       "long_words_only                                                               \n",
       "horses and asses purebred breeding male live                           1      \n",
       "horses and asses purebred breeding female live                         0      \n",
       "horses imported for immediate slaughter live except purebred breeding  0      \n",
       "horses live nesoi                                                      0      \n",
       "asses live                                                             0      \n",
       "\n",
       "                                                                       nesoi  \\\n",
       "long_words_only                                                                \n",
       "horses and asses purebred breeding male live                           0       \n",
       "horses and asses purebred breeding female live                         0       \n",
       "horses imported for immediate slaughter live except purebred breeding  0       \n",
       "horses live nesoi                                                      1       \n",
       "asses live                                                             0       \n",
       "\n",
       "                                                                       purebred  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           1          \n",
       "horses and asses purebred breeding female live                         1          \n",
       "horses imported for immediate slaughter live except purebred breeding  1          \n",
       "horses live nesoi                                                      0          \n",
       "asses live                                                             0          \n",
       "\n",
       "                                                                       slaughter  \n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0          \n",
       "horses and asses purebred breeding female live                         0          \n",
       "horses imported for immediate slaughter live except purebred breeding  1          \n",
       "horses live nesoi                                                      0          \n",
       "asses live                                                             0          "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't worry about this, it's for pedagogical purposes\n",
    "columns = [x[0] for x in sorted(list(cv.vocabulary_.items()), key=lambda x: x[1])]\n",
    "pd.DataFrame(tfd.toarray(), columns=columns, index=first_few_only['long_words_only'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we get the idea, let's do this for the entire dataset and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28469x12054 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 347471 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit_transform(df[\"long_words_only\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't try to convert this into an array as above, because it would be very memory-intensive. But we can see we have 12,054 unique words.\n",
    "\n",
    "Now, we have variables. But what what exactly are we going to model? The trade-off is that the more digits of the HS code we use, the fewer records there are within each code that the model can learn from. We aren't using any heirarchical information here, so each HS code is a completely separate category from the model's perspective. Let's extract 2-digit, 4-digit, and 6-digit harmonized codes in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>290.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>411.851396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>85.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>307.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2904.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               HS2\n",
       "count  98.000000  \n",
       "mean   290.500000 \n",
       "std    411.851396 \n",
       "min    2.000000   \n",
       "25%    85.250000  \n",
       "50%    160.000000 \n",
       "75%    307.500000 \n",
       "max    2904.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b061f618b00>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"HS2\"] = df[\"HS10\"].str[:2]\n",
    "df[\"HS4\"] = df[\"HS10\"].str[:4]\n",
    "df[\"HS6\"] = df[\"HS10\"].str[:6]\n",
    "\n",
    "# we'll look at the distribution of # of records in each class at the 4-digit level.\n",
    "# Remember, we haven't de-duplicated, so this estimate is a bit high\n",
    "df.HS2.value_counts().hist()\n",
    "df.HS2.value_counts().describe().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some categories do have only 2 descriptions. Let's see how many there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 codes with only 2 descs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99    2\n",
       "Name: HS2, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcs = df.HS2.value_counts()\n",
    "print(len(vcs[vcs == 2]), \"codes with only 2 descs\")\n",
    "vcs[vcs == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 99 looks to be a very specific category, so we'd probably want to think more carfeully before classifying those. \n",
    "\n",
    "\n",
    "#### Training / test sets\n",
    "As a bare minimum, we need at least 2 records in any category we want to attempt to model. This is because we need to split our data into two pieces: the _training set_, which we'll develop the model on, and the _test set_, which we'll subsequently evaluate it on. We want to see how the model performs on descriptions it's never seen before.\n",
    "\n",
    "In practice, we almost certainly want more than 2, but we'll continue along here.\n",
    "\n",
    "In addition, [_cross validation_](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6), which we won't get into today, is an important technique in machine learning that prevents us from \"overfitting\" the model to the sample of data we're using. It's easy to do in python with `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initially, we have 28469 records\n",
      "after deduping, we have 22372 records\n",
      "after removing <3 record categories, there are 22370 records\n",
      "training set has 16777 records -- 74.99776486365668 percent -- and test set has 5593 records\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we make these functions so we can reuse them later\n",
    "def make_test_train(df, column_name, y_column):\n",
    "    # first, let's remove duplicates\n",
    "    print(\"initially, we have\", len(df), \"records\")\n",
    "    deduped = df.drop_duplicates(subset=[\"long_words_only\"])\n",
    "    print(\"after deduping, we have\", len(deduped), \"records\")\n",
    "\n",
    "    #now, let's remove any HS4 category with <2 records\n",
    "    vcs = deduped[y_column].value_counts()\n",
    "    to_include = vcs[vcs > 2].index\n",
    "    final_dataset = deduped[deduped[y_column].isin(to_include)]\n",
    "    print(\"after removing <3 record categories, there are\", len(final_dataset), \"records\")\n",
    "\n",
    "    # the stratify is important -- \n",
    "    # it's making sure that we have an instance of each category in both the train and test sets\n",
    "\n",
    "    train, test = train_test_split(final_dataset, stratify=final_dataset[y_column], random_state=42)\n",
    "    print(\"training set has\", len(train), \"records --\", 100 * len(train) / len(final_dataset), \n",
    "          \"percent -- and test set has\", len(test), \"records\")\n",
    "    \n",
    "    return train, test\n",
    "train, test = make_test_train(df, \"long_words_only\", \"HS2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split up our data, we can choose a classifier. We'll use one of the simplest out there: Logistic Regression, often known as \"logit.\" Normally, logistic regression is a binary classifier. In our case, because we're categorizing something like 1200 codes, we'll actually be training 1200 models, and selecting the highest-probability prediction. This is known as \"one-vs-all\". There are other voting schemes to convert binary classifiers into multi-class classifiers.\n",
    "\n",
    "One more trick: instead of using the closed-form logistic regression classifier, we'll use a heuristic optimization approach that runs much more quickly and efficiently, called \"stochastic gradient descent.\" SGD, as it's abbreviated, is part of the core technique used to optimize neural nets (back-propagation or \"backprop\") as well. We'll leave it to you to convince yourself that this approach is just as good. You can get into the math or just try it out in Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def make_model(train, vec, column_name, y_column, loss='log', alpha=.0001):\n",
    "    X = vec.fit_transform(train[column_name])\n",
    "    y = train[y_column]\n",
    "\n",
    "    clf = SGDClassifier(n_jobs=NCPUS, alpha=alpha, loss=loss,\n",
    "                        penalty='l2', max_iter=5000, tol=1e-5,\n",
    "                        random_state=42)\n",
    "    clf.fit(X, y)\n",
    "    return clf, vec\n",
    "clf, vec = make_model(train, CountVectorizer(), \"long_words_only\", \"HS2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a trained model in the `clf` variable. Let's see how it does on a simple metric: overall accuracy. That is, \"out of every code the model predicted, what fraction did it get right?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample accuracy:  0.959706741372\n",
      "test set accuracy:  0.905059896299\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(clf, vec, train, test, column_name, y_column):\n",
    "    X = vec.transform(train[column_name])\n",
    "    y = train[y_column]\n",
    "    X_test = vec.transform(test[column_name])\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_true = test[y_column]\n",
    "    print(\"in-sample accuracy: \", (clf.predict(X) == y).mean())\n",
    "    print(\"test set accuracy: \", (y_test_pred == y_test_true).mean())\n",
    "    return y_test_true, y_test_pred\n",
    "    \n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_words_only\", \"HS2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Now, we can drill down a bit in a few ways. A productive way to do so is to look at failing codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         01       0.92      1.00      0.96        22\n",
      "         02       1.00      0.96      0.98        53\n",
      "         03       0.93      0.97      0.95       158\n",
      "         04       0.95      0.96      0.95        74\n",
      "         05       1.00      0.33      0.50        12\n",
      "         06       1.00      0.87      0.93        15\n",
      "         07       0.98      1.00      0.99        85\n",
      "         08       0.90      0.98      0.94        57\n",
      "         09       0.95      0.82      0.88        22\n",
      "         10       0.94      0.84      0.89        19\n",
      "         11       0.72      0.93      0.81        14\n",
      "         12       0.93      0.88      0.90        42\n",
      "         13       1.00      0.14      0.25         7\n",
      "         14       0.75      0.75      0.75         4\n",
      "         15       0.96      0.87      0.91        30\n",
      "         16       0.92      0.80      0.86        56\n",
      "         17       0.96      0.92      0.94        26\n",
      "         18       0.85      1.00      0.92        23\n",
      "         19       1.00      0.73      0.85        30\n",
      "         20       0.90      0.96      0.93        79\n",
      "         21       0.96      0.68      0.79        34\n",
      "         22       1.00      0.85      0.92        33\n",
      "         23       1.00      0.76      0.87        17\n",
      "         24       1.00      0.98      0.99        57\n",
      "         25       0.75      0.52      0.61        29\n",
      "         26       0.90      0.93      0.92        30\n",
      "         27       0.85      0.72      0.78        40\n",
      "         28       0.88      0.71      0.79        90\n",
      "         29       0.62      0.97      0.75       330\n",
      "         30       0.95      0.68      0.79        28\n",
      "         31       1.00      0.50      0.67         8\n",
      "         32       0.97      0.72      0.83        47\n",
      "         33       1.00      0.76      0.86        21\n",
      "         34       0.90      0.64      0.75        14\n",
      "         35       1.00      0.44      0.62         9\n",
      "         36       1.00      0.40      0.57         5\n",
      "         37       1.00      0.94      0.97        18\n",
      "         38       0.76      0.57      0.65        56\n",
      "         39       0.85      0.76      0.80        89\n",
      "         40       0.96      0.93      0.95        58\n",
      "         41       0.98      1.00      0.99        51\n",
      "         42       0.97      0.89      0.93        35\n",
      "         43       1.00      1.00      1.00        11\n",
      "         44       0.96      0.96      0.96       142\n",
      "         45       1.00      0.83      0.91         6\n",
      "         46       1.00      0.93      0.96        14\n",
      "         47       1.00      0.71      0.83         7\n",
      "         48       0.95      0.99      0.97        91\n",
      "         49       0.90      0.64      0.75        14\n",
      "         50       1.00      0.78      0.88         9\n",
      "         51       0.97      0.97      0.97        37\n",
      "         52       0.98      1.00      0.99       157\n",
      "         53       1.00      1.00      1.00        17\n",
      "         54       0.98      1.00      0.99        81\n",
      "         55       0.99      1.00      1.00       118\n",
      "         56       1.00      0.96      0.98        25\n",
      "         57       1.00      0.96      0.98        23\n",
      "         58       0.94      0.94      0.94        34\n",
      "         59       0.95      0.91      0.93        22\n",
      "         60       1.00      1.00      1.00        33\n",
      "         61       0.89      0.98      0.93       248\n",
      "         62       0.98      0.91      0.94       346\n",
      "         63       0.98      0.91      0.95        69\n",
      "         64       0.98      1.00      0.99       109\n",
      "         65       1.00      1.00      1.00        18\n",
      "         66       0.00      0.00      0.00         2\n",
      "         67       1.00      0.75      0.86         4\n",
      "         68       0.64      0.62      0.63        29\n",
      "         69       0.97      0.81      0.88        36\n",
      "         70       0.92      0.96      0.94        68\n",
      "         71       0.97      0.93      0.95        41\n",
      "         72       0.98      0.95      0.97       165\n",
      "         73       0.95      0.99      0.97       169\n",
      "         74       0.91      0.93      0.92        44\n",
      "         75       0.75      1.00      0.86         9\n",
      "         76       0.92      1.00      0.96        36\n",
      "         78       0.67      0.67      0.67         3\n",
      "         79       1.00      1.00      1.00         4\n",
      "         80       1.00      0.25      0.40         4\n",
      "         81       0.90      0.90      0.90        20\n",
      "         82       0.84      0.81      0.83        59\n",
      "         83       1.00      0.84      0.91        25\n",
      "         84       0.91      0.95      0.93       461\n",
      "         85       0.89      0.92      0.90       269\n",
      "         86       1.00      0.67      0.80         9\n",
      "         87       0.94      0.93      0.94       107\n",
      "         88       1.00      0.73      0.85        15\n",
      "         89       1.00      0.55      0.71        11\n",
      "         90       0.87      0.77      0.81       128\n",
      "         91       0.99      1.00      1.00       105\n",
      "         92       1.00      0.74      0.85        19\n",
      "         93       0.86      0.60      0.71        20\n",
      "         94       0.87      0.88      0.87        66\n",
      "         95       0.95      0.64      0.76        33\n",
      "         96       0.87      0.72      0.79        46\n",
      "         97       0.00      0.00      0.00         5\n",
      "         98       1.00      0.65      0.79        23\n",
      "\n",
      "avg / total       0.92      0.91      0.90      5593\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "print(classification_report(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at codes with >= 100 samples can see chapter 29 is performing poorly. Let's investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_words_only</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>limestone except pebbles and gravel</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>bauxite calcined refractory grade</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>toluene</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>quebracho extract</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>particle accelerator parts</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>imitation gemstones</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>trisodium phosphate</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>flashlights</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>nitric acid and sulfonitric acids</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>waterbed mattresses and liners and parts of the foregoing</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>butter nesoi</td>\n",
       "      <td>04</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>peptones and their derivatives other protein substances and their derivatives and hide powder whether or not chromed nesoi</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>ferroniobium nesoi</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>telephones for cellular networks or for other wireless networks nesoi</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>golf clubs complete</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>coffee husks and skins</td>\n",
       "      <td>09</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>paintballs</td>\n",
       "      <td>93</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>manostats</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>herrings kipper snacks</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>squash rackets</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>bis 1 2 2 6 6 pentamethyl 4 piperidinyl sebacate</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>cerium compounds</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>norway lobsters nephrops norvegicus nesoi</td>\n",
       "      <td>03</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>ambergris castoreum civet and musk</td>\n",
       "      <td>05</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>sulfathiazole and sulfathiazole sodium</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>chrysotile crudes</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>extracts of glands or other organs or of their secretions</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>metaldehyde powder or crystal form</td>\n",
       "      <td>29</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>inflatable rafts</td>\n",
       "      <td>89</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>other vitamins synthesized from aromatic or modified aromatic industrial organic compounds nesoi</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>mixtures of n chloro phenyl amino carbonyl 2 6 difluorobenzamide and inert substances</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>nonrefactory mortars and conretes except wet</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>malt extract solid or condensed</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>synthetic organic tanning substances aromatic or modified aromatic</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>other calcareous stone nesoi</td>\n",
       "      <td>68</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>disinfectants</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>polyphosphoric acids</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>polyisobutylene nesoi</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>combination antibiotics containing penicllins or derivatives thereof with a penicillanic acid structure or streptomycins or their derivatives nesoi</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>n vinyl 2 pyrrolidone monomer</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>ephedra</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>international customs forms carnets and parts thereof in english or french whether or not in additional languages</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>other including natural concentrates</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5206</th>\n",
       "      <td>ammonium dihydrogenorthophosphate monoammonium phosphate</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>n 2 2 6 dicyano 4 methylphenylazo 5 diethylamino phenyl methanesulfonamide and n 2 2 6 dicyano 4 methyl phenylazo 5 di 1 propylamino phenyl m</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5212</th>\n",
       "      <td>gum arabic</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>catalytic converters</td>\n",
       "      <td>84</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>sulfur monochloride</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>pectic substances pectinates and pectates</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>4 4 isopropylidenedicyclohexanol and mixtures contg not less than 90 by weight of stereoisomers of 2 isopropyl 5 methylcyclohexanol</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>national flags of nations other than the united states</td>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>vermiculite perlite and chlorites unexpanded</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>contact lenses</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>parts and accessories of rifle nesoi</td>\n",
       "      <td>93</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>racquetball rackets</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>diammonium hydrogenorthophosphate diammonium phosphate</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>carbonyl dichloride phosgene</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5503</th>\n",
       "      <td>colloidal precious metals</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>dibutyltin oxide</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>tumeric curcuma</td>\n",
       "      <td>09</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          long_words_only  \\\n",
       "47    limestone except pebbles and gravel                                                                                                                   \n",
       "57    bauxite calcined refractory grade                                                                                                                     \n",
       "60    toluene                                                                                                                                               \n",
       "61    quebracho extract                                                                                                                                     \n",
       "97    particle accelerator parts                                                                                                                            \n",
       "126   imitation gemstones                                                                                                                                   \n",
       "169   trisodium phosphate                                                                                                                                   \n",
       "226   flashlights                                                                                                                                           \n",
       "229   nitric acid and sulfonitric acids                                                                                                                     \n",
       "234   waterbed mattresses and liners and parts of the foregoing                                                                                             \n",
       "238   butter nesoi                                                                                                                                          \n",
       "243   peptones and their derivatives other protein substances and their derivatives and hide powder whether or not chromed nesoi                            \n",
       "294   ferroniobium nesoi                                                                                                                                    \n",
       "298   telephones for cellular networks or for other wireless networks nesoi                                                                                 \n",
       "302   golf clubs complete                                                                                                                                   \n",
       "305   coffee husks and skins                                                                                                                                \n",
       "307   paintballs                                                                                                                                            \n",
       "343   manostats                                                                                                                                             \n",
       "359   herrings kipper snacks                                                                                                                                \n",
       "364   squash rackets                                                                                                                                        \n",
       "365   bis 1 2 2 6 6 pentamethyl 4 piperidinyl sebacate                                                                                                      \n",
       "400   cerium compounds                                                                                                                                      \n",
       "431   norway lobsters nephrops norvegicus nesoi                                                                                                             \n",
       "432   ambergris castoreum civet and musk                                                                                                                    \n",
       "465   sulfathiazole and sulfathiazole sodium                                                                                                                \n",
       "492   chrysotile crudes                                                                                                                                     \n",
       "535   extracts of glands or other organs or of their secretions                                                                                             \n",
       "565   metaldehyde powder or crystal form                                                                                                                    \n",
       "570   inflatable rafts                                                                                                                                      \n",
       "593   other vitamins synthesized from aromatic or modified aromatic industrial organic compounds nesoi                                                      \n",
       "...                                                                                                ...                                                      \n",
       "4807  mixtures of n chloro phenyl amino carbonyl 2 6 difluorobenzamide and inert substances                                                                 \n",
       "4809  nonrefactory mortars and conretes except wet                                                                                                          \n",
       "4822  malt extract solid or condensed                                                                                                                       \n",
       "4840  synthetic organic tanning substances aromatic or modified aromatic                                                                                    \n",
       "4859  other calcareous stone nesoi                                                                                                                          \n",
       "4888  disinfectants                                                                                                                                         \n",
       "4982  polyphosphoric acids                                                                                                                                  \n",
       "5018  polyisobutylene nesoi                                                                                                                                 \n",
       "5026  combination antibiotics containing penicllins or derivatives thereof with a penicillanic acid structure or streptomycins or their derivatives nesoi   \n",
       "5029  n vinyl 2 pyrrolidone monomer                                                                                                                         \n",
       "5087  ephedra                                                                                                                                               \n",
       "5115  international customs forms carnets and parts thereof in english or french whether or not in additional languages                                     \n",
       "5170  other including natural concentrates                                                                                                                  \n",
       "5206  ammonium dihydrogenorthophosphate monoammonium phosphate                                                                                              \n",
       "5211  n 2 2 6 dicyano 4 methylphenylazo 5 diethylamino phenyl methanesulfonamide and n 2 2 6 dicyano 4 methyl phenylazo 5 di 1 propylamino phenyl m         \n",
       "5212  gum arabic                                                                                                                                            \n",
       "5245  catalytic converters                                                                                                                                  \n",
       "5268  sulfur monochloride                                                                                                                                   \n",
       "5271  pectic substances pectinates and pectates                                                                                                             \n",
       "5333  4 4 isopropylidenedicyclohexanol and mixtures contg not less than 90 by weight of stereoisomers of 2 isopropyl 5 methylcyclohexanol                   \n",
       "5377  national flags of nations other than the united states                                                                                                \n",
       "5388  vermiculite perlite and chlorites unexpanded                                                                                                          \n",
       "5389  contact lenses                                                                                                                                        \n",
       "5390  parts and accessories of rifle nesoi                                                                                                                  \n",
       "5425  racquetball rackets                                                                                                                                   \n",
       "5464  diammonium hydrogenorthophosphate diammonium phosphate                                                                                                \n",
       "5471  carbonyl dichloride phosgene                                                                                                                          \n",
       "5503  colloidal precious metals                                                                                                                             \n",
       "5504  dibutyltin oxide                                                                                                                                      \n",
       "5523  tumeric curcuma                                                                                                                                       \n",
       "\n",
       "     HS2 pred  \n",
       "47    25  29   \n",
       "57    26  29   \n",
       "60    27  29   \n",
       "61    32  29   \n",
       "97    85  29   \n",
       "126   39  29   \n",
       "169   28  29   \n",
       "226   85  29   \n",
       "229   28  29   \n",
       "234   39  29   \n",
       "238   04  29   \n",
       "243   35  29   \n",
       "294   72  29   \n",
       "298   85  29   \n",
       "302   95  29   \n",
       "305   09  29   \n",
       "307   93  29   \n",
       "343   90  29   \n",
       "359   16  29   \n",
       "364   95  29   \n",
       "365   38  29   \n",
       "400   28  29   \n",
       "431   03  29   \n",
       "432   05  29   \n",
       "465   29  28   \n",
       "492   25  29   \n",
       "535   30  29   \n",
       "565   29  71   \n",
       "570   89  29   \n",
       "593   30  29   \n",
       "...   ..  ..   \n",
       "4807  38  29   \n",
       "4809  38  29   \n",
       "4822  19  29   \n",
       "4840  32  29   \n",
       "4859  68  29   \n",
       "4888  38  29   \n",
       "4982  28  29   \n",
       "5018  39  29   \n",
       "5026  30  29   \n",
       "5029  29  39   \n",
       "5087  12  29   \n",
       "5115  49  29   \n",
       "5170  29  25   \n",
       "5206  31  29   \n",
       "5211  32  29   \n",
       "5212  13  29   \n",
       "5245  84  29   \n",
       "5268  28  29   \n",
       "5271  13  29   \n",
       "5333  29  38   \n",
       "5377  63  29   \n",
       "5388  25  29   \n",
       "5389  90  29   \n",
       "5390  93  29   \n",
       "5425  95  29   \n",
       "5464  31  29   \n",
       "5471  28  29   \n",
       "5503  28  29   \n",
       "5504  29  28   \n",
       "5523  09  29   \n",
       "\n",
       "[209 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_words_only\", \"HS2\", \"pred\"]\n",
    "CODE = \"29\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "test_reset[cond1 & cond2][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here? It's likely that 29 is the \"default\" prediction. This makes sense, because the category is both large and full of obscure chemical words. The model can likely figure out other chapters more easily, so it's a smart strategy to, upon seeing an unknown word, pick the category with the largest variety of complex words. We can test this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['29'],\n",
       "      dtype='<U2')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get the vector for a word the model has never seen before\n",
    "x = vec.transform([\"thiswordisgibberish\"])\n",
    "clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems this intuition is correct.\n",
    "\n",
    "One interesting result is that \"racquetball rackets\" gets predicted to code 29. What's going on there? Let's check out the training set to see how frequently the words \"racquetball\" and \"racket\" occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS10</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>long_words_only</th>\n",
       "      <th>HS2</th>\n",
       "      <th>HS4</th>\n",
       "      <th>HS6</th>\n",
       "      <th>long_no_stopwords</th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17348</th>\n",
       "      <td>8708806510</td>\n",
       "      <td>BEAM HANGER BRACKETS,NESOI,OF MOTOR VEHICLES,NESOI</td>\n",
       "      <td>BEAM HANGER BRACKETS FOR SUSPENSION SYSTEMS, NESOI, OF THE MOTOR VEHICLES OF HEADING 8701 - 8705</td>\n",
       "      <td>beam hanger brackets for suspension systems nesoi of the motor vehicles of heading 8701 8705</td>\n",
       "      <td>87</td>\n",
       "      <td>8708</td>\n",
       "      <td>870880</td>\n",
       "      <td>beam hanger brackets suspension systems motor vehicles heading 8701 8705</td>\n",
       "      <td>beam hanger bracket suspens system motor vehicl head 8701 8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18793</th>\n",
       "      <td>9506516000</td>\n",
       "      <td>PARTS AND ACCESSORIES FOR LAWN-TENNIS</td>\n",
       "      <td>PARTS AND ACCESSORIES FOR LAWN-TENNIS RACKETS</td>\n",
       "      <td>parts and accessories for lawn tennis rackets</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950651</td>\n",
       "      <td>lawn tennis rackets</td>\n",
       "      <td>lawn tenni racket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18791</th>\n",
       "      <td>9506512000</td>\n",
       "      <td>LAWN-TENNIS RACKETS, STRUNG</td>\n",
       "      <td>LAWN-TENNIS RACKETS, STRUNG</td>\n",
       "      <td>lawn tennis rackets strung</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950651</td>\n",
       "      <td>lawn tennis rackets strung</td>\n",
       "      <td>lawn tenni racket strung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18792</th>\n",
       "      <td>9506514000</td>\n",
       "      <td>LAWN-TENNIS RACKETS, NOT STRUNG</td>\n",
       "      <td>LAWN-TENNIS RACKETS, NOT STRUNG</td>\n",
       "      <td>lawn tennis rackets not strung</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950651</td>\n",
       "      <td>lawn tennis rackets strung</td>\n",
       "      <td>lawn tenni racket strung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14524</th>\n",
       "      <td>8302500000</td>\n",
       "      <td>HAT-RACKS HAT PEGS BRCKTS ETC PARTS, BASE METAL</td>\n",
       "      <td>HAT-RACKS, HAT PEGS, BRACKETS AND SIMILAR FIXTURES, AND PARTS THEREOF, OF BASE METAL</td>\n",
       "      <td>hat racks hat pegs brackets and similar fixtures and parts thereof of base metal</td>\n",
       "      <td>83</td>\n",
       "      <td>8302</td>\n",
       "      <td>830250</td>\n",
       "      <td>hat racks hat pegs brackets similar fixtures base metal</td>\n",
       "      <td>hat rack hat peg bracket similar fixtur base metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18798</th>\n",
       "      <td>9506598060</td>\n",
       "      <td>RACKETS STRUNG OR NOT, INCLUDING PTS ETC., NESOI</td>\n",
       "      <td>RACKETS WHETHER OR NOT STRUNG, INCLUDING PARTS AND ACCESSORIES, NESOI</td>\n",
       "      <td>rackets whether or not strung including parts and accessories nesoi</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950659</td>\n",
       "      <td>rackets whether strung</td>\n",
       "      <td>racket whether strung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28360</th>\n",
       "      <td>9506511000</td>\n",
       "      <td>LAWN-TENNIS RACKETS, WHETHER OR NOT STRUNG</td>\n",
       "      <td>LAWN-TENNIS RACKETS, WHETHER OR NOT STRUNG</td>\n",
       "      <td>lawn tennis rackets whether or not strung</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950651</td>\n",
       "      <td>lawn tennis rackets whether strung</td>\n",
       "      <td>lawn tenni racket whether strung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18728</th>\n",
       "      <td>9405916040</td>\n",
       "      <td>LAMPS PARTS PRISMS &amp; OTHER GLASS ARTICLES</td>\n",
       "      <td>LAMPS PARTS, PRISMS AND OTHER GLASS ARTICLES OF A KIND USE IN CHANDELIERS AND WALL BRACKETS, AND ARTICLES THEREOF</td>\n",
       "      <td>lamps parts prisms and other glass articles of a kind use in chandeliers and wall brackets and articles thereof</td>\n",
       "      <td>94</td>\n",
       "      <td>9405</td>\n",
       "      <td>940591</td>\n",
       "      <td>lamps prisms glass articles kind use chandeliers wall brackets articles</td>\n",
       "      <td>lamp prism glass articl kind use chandeli wall bracket articl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18794</th>\n",
       "      <td>9506594040</td>\n",
       "      <td>BADMINTON RACKETS AND RACKET FRAMES</td>\n",
       "      <td>BADMINTON RACKETS AND RACKET FRAMES</td>\n",
       "      <td>badminton rackets and racket frames</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950659</td>\n",
       "      <td>badminton rackets racket frames</td>\n",
       "      <td>badminton racket racket frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18822</th>\n",
       "      <td>9506991200</td>\n",
       "      <td>BADMINTON ARTICLES &amp; EQUIP EXC RACKETS &amp; PTS,NESOI</td>\n",
       "      <td>BADMINTON ARTICLES AND EQUIPMENT EXCEPT RACKETS AND PARTS AND ACCESSORIES THEREOF, NESOI</td>\n",
       "      <td>badminton articles and equipment except rackets and parts and accessories thereof nesoi</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950699</td>\n",
       "      <td>badminton articles equipment rackets</td>\n",
       "      <td>badminton articl equip racket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             HS10                                           short_desc  \\\n",
       "17348  8708806510  BEAM HANGER BRACKETS,NESOI,OF MOTOR VEHICLES,NESOI    \n",
       "18793  9506516000  PARTS AND ACCESSORIES FOR LAWN-TENNIS                 \n",
       "18791  9506512000  LAWN-TENNIS RACKETS, STRUNG                           \n",
       "18792  9506514000  LAWN-TENNIS RACKETS, NOT STRUNG                       \n",
       "14524  8302500000  HAT-RACKS HAT PEGS BRCKTS ETC PARTS, BASE METAL       \n",
       "18798  9506598060  RACKETS STRUNG OR NOT, INCLUDING PTS ETC., NESOI      \n",
       "28360  9506511000  LAWN-TENNIS RACKETS, WHETHER OR NOT STRUNG            \n",
       "18728  9405916040  LAMPS PARTS PRISMS & OTHER GLASS ARTICLES             \n",
       "18794  9506594040  BADMINTON RACKETS AND RACKET FRAMES                   \n",
       "18822  9506991200  BADMINTON ARTICLES & EQUIP EXC RACKETS & PTS,NESOI    \n",
       "\n",
       "                                                                                                                                                    long_desc  \\\n",
       "17348  BEAM HANGER BRACKETS FOR SUSPENSION SYSTEMS, NESOI, OF THE MOTOR VEHICLES OF HEADING 8701 - 8705                                                         \n",
       "18793  PARTS AND ACCESSORIES FOR LAWN-TENNIS RACKETS                                                                                                            \n",
       "18791  LAWN-TENNIS RACKETS, STRUNG                                                                                                                              \n",
       "18792  LAWN-TENNIS RACKETS, NOT STRUNG                                                                                                                          \n",
       "14524  HAT-RACKS, HAT PEGS, BRACKETS AND SIMILAR FIXTURES, AND PARTS THEREOF, OF BASE METAL                                                                     \n",
       "18798  RACKETS WHETHER OR NOT STRUNG, INCLUDING PARTS AND ACCESSORIES, NESOI                                                                                    \n",
       "28360  LAWN-TENNIS RACKETS, WHETHER OR NOT STRUNG                                                                                                               \n",
       "18728  LAMPS PARTS, PRISMS AND OTHER GLASS ARTICLES OF A KIND USE IN CHANDELIERS AND WALL BRACKETS, AND ARTICLES THEREOF                                        \n",
       "18794  BADMINTON RACKETS AND RACKET FRAMES                                                                                                                      \n",
       "18822  BADMINTON ARTICLES AND EQUIPMENT EXCEPT RACKETS AND PARTS AND ACCESSORIES THEREOF, NESOI                                                                 \n",
       "\n",
       "                                                                                                       long_words_only  \\\n",
       "17348  beam hanger brackets for suspension systems nesoi of the motor vehicles of heading 8701 8705                      \n",
       "18793  parts and accessories for lawn tennis rackets                                                                     \n",
       "18791  lawn tennis rackets strung                                                                                        \n",
       "18792  lawn tennis rackets not strung                                                                                    \n",
       "14524  hat racks hat pegs brackets and similar fixtures and parts thereof of base metal                                  \n",
       "18798  rackets whether or not strung including parts and accessories nesoi                                               \n",
       "28360  lawn tennis rackets whether or not strung                                                                         \n",
       "18728  lamps parts prisms and other glass articles of a kind use in chandeliers and wall brackets and articles thereof   \n",
       "18794  badminton rackets and racket frames                                                                               \n",
       "18822  badminton articles and equipment except rackets and parts and accessories thereof nesoi                           \n",
       "\n",
       "      HS2   HS4     HS6  \\\n",
       "17348  87  8708  870880   \n",
       "18793  95  9506  950651   \n",
       "18791  95  9506  950651   \n",
       "18792  95  9506  950651   \n",
       "14524  83  8302  830250   \n",
       "18798  95  9506  950659   \n",
       "28360  95  9506  950651   \n",
       "18728  94  9405  940591   \n",
       "18794  95  9506  950659   \n",
       "18822  95  9506  950699   \n",
       "\n",
       "                                                              long_no_stopwords  \\\n",
       "17348  beam hanger brackets suspension systems motor vehicles heading 8701 8705   \n",
       "18793  lawn tennis rackets                                                        \n",
       "18791  lawn tennis rackets strung                                                 \n",
       "18792  lawn tennis rackets strung                                                 \n",
       "14524  hat racks hat pegs brackets similar fixtures base metal                    \n",
       "18798  rackets whether strung                                                     \n",
       "28360  lawn tennis rackets whether strung                                         \n",
       "18728  lamps prisms glass articles kind use chandeliers wall brackets articles    \n",
       "18794  badminton rackets racket frames                                            \n",
       "18822  badminton articles equipment rackets                                       \n",
       "\n",
       "                                            long_no_stopwords_stemmed  \n",
       "17348  beam hanger bracket suspens system motor vehicl head 8701 8705  \n",
       "18793  lawn tenni racket                                               \n",
       "18791  lawn tenni racket strung                                        \n",
       "18792  lawn tenni racket strung                                        \n",
       "14524  hat rack hat peg bracket similar fixtur base metal              \n",
       "18798  racket whether strung                                           \n",
       "28360  lawn tenni racket whether strung                                \n",
       "18728  lamp prism glass articl kind use chandeli wall bracket articl   \n",
       "18794  badminton racket racket frame                                   \n",
       "18822  badminton articl equip racket                                   "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"long_words_only\"].str.contains(\"racket\") | train[\"long_words_only\"].str.contains(\"racquetball\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Racquetball\" isn't there, but \"racket\" is, and we'd hope that would be enough information (it certainly is for a human). It may be the case that some of these other words are polluting the model's ability to grasp the importance of the word racket. Let's remove some of them using a common NLP technique. The idea is that we want to remove some of the most commonly occurring words immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "all_stopwords = set(stopwords.words('english'))\n",
    "all_stopwords.add(\"nesoi\")\n",
    "all_stopwords.add(\"excluding\")\n",
    "all_stopwords.add(\"except\")\n",
    "all_stopwords.add(\"including\")\n",
    "all_stopwords.add(\"thereof\")\n",
    "all_stopwords.add(\"parts\")\n",
    "all_stopwords.add(\"accessories\")\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(desc):\n",
    "    return \" \".join(d for d in desc.split() if d not in all_stopwords)\n",
    "df[\"long_no_stopwords\"] = df[\"long_words_only\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initially, we have 28469 records\n",
      "after deduping, we have 22372 records\n",
      "after removing <3 record categories, there are 22370 records\n",
      "training set has 16777 records -- 74.99776486365668 percent -- and test set has 5593 records\n",
      "in-sample accuracy:  0.959706741372\n",
      "test set accuracy:  0.905059896299\n"
     ]
    }
   ],
   "source": [
    "train, test = make_test_train(df, \"long_no_stopwords\", \"HS2\")\n",
    "clf, vec = make_model(train, CountVectorizer(binary=True), \"long_no_stopwords\", \"HS2\")\n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_no_stopwords\", \"HS2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps marginally worse performance, but with a decrease this small, this could simply be a function of the random train/test split we chose. Without further investigation, I'd say this had no improvement either way on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_no_stopwords</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>squash rackets</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>racquetball rackets</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        long_no_stopwords HS2 pred\n",
       "364   squash rackets       95  29 \n",
       "5425  racquetball rackets  95  29 "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_no_stopwords\", \"HS2\", \"pred\"]\n",
    "CODE = \"29\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "cond3 = (test_reset[cols[0]].str.contains(\"racket\"))\n",
    "test_reset[cond1 & cond2 & cond3][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, we still see that the \"racquetball rackets\" description is mispredicted in the exact same way. \n",
    "\n",
    "Something else we can try is \"stemming\" -- the idea is, we want to exploit the fact that english words that convey the same meaning can have different suffixes. For example, maybe if we turn all instances of \"rackets\" to the standardized \"racket\", we'll see some improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initially, we have 28469 records\n",
      "after deduping, we have 22372 records\n",
      "after removing <3 record categories, there are 22370 records\n",
      "training set has 16777 records -- 74.99776486365668 percent -- and test set has 5593 records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS10</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>long_words_only</th>\n",
       "      <th>HS2</th>\n",
       "      <th>HS4</th>\n",
       "      <th>HS6</th>\n",
       "      <th>long_no_stopwords</th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17348</th>\n",
       "      <td>8708806510</td>\n",
       "      <td>BEAM HANGER BRACKETS,NESOI,OF MOTOR VEHICLES,NESOI</td>\n",
       "      <td>BEAM HANGER BRACKETS FOR SUSPENSION SYSTEMS, NESOI, OF THE MOTOR VEHICLES OF HEADING 8701 - 8705</td>\n",
       "      <td>beam hanger brackets for suspension systems nesoi of the motor vehicles of heading 8701 8705</td>\n",
       "      <td>87</td>\n",
       "      <td>8708</td>\n",
       "      <td>870880</td>\n",
       "      <td>beam hanger brackets suspension systems motor vehicles heading 8701 8705</td>\n",
       "      <td>beam hanger bracket suspens system motor vehicl head 8701 8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18793</th>\n",
       "      <td>9506516000</td>\n",
       "      <td>PARTS AND ACCESSORIES FOR LAWN-TENNIS</td>\n",
       "      <td>PARTS AND ACCESSORIES FOR LAWN-TENNIS RACKETS</td>\n",
       "      <td>parts and accessories for lawn tennis rackets</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950651</td>\n",
       "      <td>lawn tennis rackets</td>\n",
       "      <td>lawn tenni racket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18791</th>\n",
       "      <td>9506512000</td>\n",
       "      <td>LAWN-TENNIS RACKETS, STRUNG</td>\n",
       "      <td>LAWN-TENNIS RACKETS, STRUNG</td>\n",
       "      <td>lawn tennis rackets strung</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950651</td>\n",
       "      <td>lawn tennis rackets strung</td>\n",
       "      <td>lawn tenni racket strung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18792</th>\n",
       "      <td>9506514000</td>\n",
       "      <td>LAWN-TENNIS RACKETS, NOT STRUNG</td>\n",
       "      <td>LAWN-TENNIS RACKETS, NOT STRUNG</td>\n",
       "      <td>lawn tennis rackets not strung</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950651</td>\n",
       "      <td>lawn tennis rackets strung</td>\n",
       "      <td>lawn tenni racket strung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14524</th>\n",
       "      <td>8302500000</td>\n",
       "      <td>HAT-RACKS HAT PEGS BRCKTS ETC PARTS, BASE METAL</td>\n",
       "      <td>HAT-RACKS, HAT PEGS, BRACKETS AND SIMILAR FIXTURES, AND PARTS THEREOF, OF BASE METAL</td>\n",
       "      <td>hat racks hat pegs brackets and similar fixtures and parts thereof of base metal</td>\n",
       "      <td>83</td>\n",
       "      <td>8302</td>\n",
       "      <td>830250</td>\n",
       "      <td>hat racks hat pegs brackets similar fixtures base metal</td>\n",
       "      <td>hat rack hat peg bracket similar fixtur base metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18798</th>\n",
       "      <td>9506598060</td>\n",
       "      <td>RACKETS STRUNG OR NOT, INCLUDING PTS ETC., NESOI</td>\n",
       "      <td>RACKETS WHETHER OR NOT STRUNG, INCLUDING PARTS AND ACCESSORIES, NESOI</td>\n",
       "      <td>rackets whether or not strung including parts and accessories nesoi</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950659</td>\n",
       "      <td>rackets whether strung</td>\n",
       "      <td>racket whether strung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28360</th>\n",
       "      <td>9506511000</td>\n",
       "      <td>LAWN-TENNIS RACKETS, WHETHER OR NOT STRUNG</td>\n",
       "      <td>LAWN-TENNIS RACKETS, WHETHER OR NOT STRUNG</td>\n",
       "      <td>lawn tennis rackets whether or not strung</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950651</td>\n",
       "      <td>lawn tennis rackets whether strung</td>\n",
       "      <td>lawn tenni racket whether strung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18728</th>\n",
       "      <td>9405916040</td>\n",
       "      <td>LAMPS PARTS PRISMS &amp; OTHER GLASS ARTICLES</td>\n",
       "      <td>LAMPS PARTS, PRISMS AND OTHER GLASS ARTICLES OF A KIND USE IN CHANDELIERS AND WALL BRACKETS, AND ARTICLES THEREOF</td>\n",
       "      <td>lamps parts prisms and other glass articles of a kind use in chandeliers and wall brackets and articles thereof</td>\n",
       "      <td>94</td>\n",
       "      <td>9405</td>\n",
       "      <td>940591</td>\n",
       "      <td>lamps prisms glass articles kind use chandeliers wall brackets articles</td>\n",
       "      <td>lamp prism glass articl kind use chandeli wall bracket articl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18794</th>\n",
       "      <td>9506594040</td>\n",
       "      <td>BADMINTON RACKETS AND RACKET FRAMES</td>\n",
       "      <td>BADMINTON RACKETS AND RACKET FRAMES</td>\n",
       "      <td>badminton rackets and racket frames</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950659</td>\n",
       "      <td>badminton rackets racket frames</td>\n",
       "      <td>badminton racket racket frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18822</th>\n",
       "      <td>9506991200</td>\n",
       "      <td>BADMINTON ARTICLES &amp; EQUIP EXC RACKETS &amp; PTS,NESOI</td>\n",
       "      <td>BADMINTON ARTICLES AND EQUIPMENT EXCEPT RACKETS AND PARTS AND ACCESSORIES THEREOF, NESOI</td>\n",
       "      <td>badminton articles and equipment except rackets and parts and accessories thereof nesoi</td>\n",
       "      <td>95</td>\n",
       "      <td>9506</td>\n",
       "      <td>950699</td>\n",
       "      <td>badminton articles equipment rackets</td>\n",
       "      <td>badminton articl equip racket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             HS10                                           short_desc  \\\n",
       "17348  8708806510  BEAM HANGER BRACKETS,NESOI,OF MOTOR VEHICLES,NESOI    \n",
       "18793  9506516000  PARTS AND ACCESSORIES FOR LAWN-TENNIS                 \n",
       "18791  9506512000  LAWN-TENNIS RACKETS, STRUNG                           \n",
       "18792  9506514000  LAWN-TENNIS RACKETS, NOT STRUNG                       \n",
       "14524  8302500000  HAT-RACKS HAT PEGS BRCKTS ETC PARTS, BASE METAL       \n",
       "18798  9506598060  RACKETS STRUNG OR NOT, INCLUDING PTS ETC., NESOI      \n",
       "28360  9506511000  LAWN-TENNIS RACKETS, WHETHER OR NOT STRUNG            \n",
       "18728  9405916040  LAMPS PARTS PRISMS & OTHER GLASS ARTICLES             \n",
       "18794  9506594040  BADMINTON RACKETS AND RACKET FRAMES                   \n",
       "18822  9506991200  BADMINTON ARTICLES & EQUIP EXC RACKETS & PTS,NESOI    \n",
       "\n",
       "                                                                                                                                                    long_desc  \\\n",
       "17348  BEAM HANGER BRACKETS FOR SUSPENSION SYSTEMS, NESOI, OF THE MOTOR VEHICLES OF HEADING 8701 - 8705                                                         \n",
       "18793  PARTS AND ACCESSORIES FOR LAWN-TENNIS RACKETS                                                                                                            \n",
       "18791  LAWN-TENNIS RACKETS, STRUNG                                                                                                                              \n",
       "18792  LAWN-TENNIS RACKETS, NOT STRUNG                                                                                                                          \n",
       "14524  HAT-RACKS, HAT PEGS, BRACKETS AND SIMILAR FIXTURES, AND PARTS THEREOF, OF BASE METAL                                                                     \n",
       "18798  RACKETS WHETHER OR NOT STRUNG, INCLUDING PARTS AND ACCESSORIES, NESOI                                                                                    \n",
       "28360  LAWN-TENNIS RACKETS, WHETHER OR NOT STRUNG                                                                                                               \n",
       "18728  LAMPS PARTS, PRISMS AND OTHER GLASS ARTICLES OF A KIND USE IN CHANDELIERS AND WALL BRACKETS, AND ARTICLES THEREOF                                        \n",
       "18794  BADMINTON RACKETS AND RACKET FRAMES                                                                                                                      \n",
       "18822  BADMINTON ARTICLES AND EQUIPMENT EXCEPT RACKETS AND PARTS AND ACCESSORIES THEREOF, NESOI                                                                 \n",
       "\n",
       "                                                                                                       long_words_only  \\\n",
       "17348  beam hanger brackets for suspension systems nesoi of the motor vehicles of heading 8701 8705                      \n",
       "18793  parts and accessories for lawn tennis rackets                                                                     \n",
       "18791  lawn tennis rackets strung                                                                                        \n",
       "18792  lawn tennis rackets not strung                                                                                    \n",
       "14524  hat racks hat pegs brackets and similar fixtures and parts thereof of base metal                                  \n",
       "18798  rackets whether or not strung including parts and accessories nesoi                                               \n",
       "28360  lawn tennis rackets whether or not strung                                                                         \n",
       "18728  lamps parts prisms and other glass articles of a kind use in chandeliers and wall brackets and articles thereof   \n",
       "18794  badminton rackets and racket frames                                                                               \n",
       "18822  badminton articles and equipment except rackets and parts and accessories thereof nesoi                           \n",
       "\n",
       "      HS2   HS4     HS6  \\\n",
       "17348  87  8708  870880   \n",
       "18793  95  9506  950651   \n",
       "18791  95  9506  950651   \n",
       "18792  95  9506  950651   \n",
       "14524  83  8302  830250   \n",
       "18798  95  9506  950659   \n",
       "28360  95  9506  950651   \n",
       "18728  94  9405  940591   \n",
       "18794  95  9506  950659   \n",
       "18822  95  9506  950699   \n",
       "\n",
       "                                                              long_no_stopwords  \\\n",
       "17348  beam hanger brackets suspension systems motor vehicles heading 8701 8705   \n",
       "18793  lawn tennis rackets                                                        \n",
       "18791  lawn tennis rackets strung                                                 \n",
       "18792  lawn tennis rackets strung                                                 \n",
       "14524  hat racks hat pegs brackets similar fixtures base metal                    \n",
       "18798  rackets whether strung                                                     \n",
       "28360  lawn tennis rackets whether strung                                         \n",
       "18728  lamps prisms glass articles kind use chandeliers wall brackets articles    \n",
       "18794  badminton rackets racket frames                                            \n",
       "18822  badminton articles equipment rackets                                       \n",
       "\n",
       "                                            long_no_stopwords_stemmed  \n",
       "17348  beam hanger bracket suspens system motor vehicl head 8701 8705  \n",
       "18793  lawn tenni racket                                               \n",
       "18791  lawn tenni racket strung                                        \n",
       "18792  lawn tenni racket strung                                        \n",
       "14524  hat rack hat peg bracket similar fixtur base metal              \n",
       "18798  racket whether strung                                           \n",
       "28360  lawn tenni racket whether strung                                \n",
       "18728  lamp prism glass articl kind use chandeli wall bracket articl   \n",
       "18794  badminton racket racket frame                                   \n",
       "18822  badminton articl equip racket                                   "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "def stem_words(desc):\n",
    "    return \" \".join(stemmer.stem(x) for x in desc.split())\n",
    "df[\"long_no_stopwords_stemmed\"] = df[\"long_no_stopwords\"].apply(stem_words)\n",
    "train, test = make_test_train(df, \"long_no_stopwords_stemmed\", \"HS2\")\n",
    "train[train[\"long_no_stopwords_stemmed\"].str.contains(\"racket\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample accuracy:  0.957322524885\n",
      "test set accuracy:  0.905775075988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_no_stopwords</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>squash rackets</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>racquetball rackets</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        long_no_stopwords HS2 pred\n",
       "364   squash rackets       95  29 \n",
       "5425  racquetball rackets  95  29 "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf, vec = make_model(train, CountVectorizer(), \"long_no_stopwords_stemmed\", \"HS2\")\n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_no_stopwords_stemmed\", \"HS2\")\n",
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_no_stopwords\", \"HS2\", \"pred\"]\n",
    "CODE = \"29\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "cond3 = (test_reset[cols[0]].str.contains(\"racket\"))\n",
    "test_reset[cond1 & cond2 & cond3][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, no improvement. It's time to try some more involved methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we can deal with situations where certain words aren't being weighted heavily enough by the model is to use a _feature scaling_ technique known as TF-IDF (term frequency - inverse document frequency). In essence, we're helping the model determine what features should be weighted and which ones should be ignored.\n",
    "\n",
    "The idea with TF-IDF is that instead of weighting each word with a 1 or 0, depending on whether or not it's in that particular record, instead we'll weight with more contextual information. There are many TF-IDF schemes, but they essentially all boil down to this:\n",
    "\n",
    "$$ \n",
    "\\frac{\\textrm{# times word occurs in record}}{\\textrm{# unique records the word occurs in}}\n",
    "$$\n",
    "\n",
    "In other words, the less frequently a word occurs across the entire set of descriptions, the more important it presumably is. Thus, since we frequently see the terms, \"nesoi\", \"prepared\", and \"preserved\",  for example, we'll weight those less\n",
    "\n",
    "Let's look at the same example with the `CountVectorizer` as above, but using the `TfidfVectorizer` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initially, we have 28469 records\n",
      "after deduping, we have 22372 records\n",
      "after removing <3 record categories, there are 22370 records\n",
      "training set has 16777 records -- 74.99776486365668 percent -- and test set has 5593 records\n",
      "in-sample accuracy:  0.878643380819\n",
      "test set accuracy:  0.837833005543\n"
     ]
    }
   ],
   "source": [
    "train, test = make_test_train(df, \"long_no_stopwords_stemmed\", \"HS2\")\n",
    "clf, vec = make_model(train, TfidfVectorizer(), \"long_no_stopwords_stemmed\", \"HS2\")\n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_no_stopwords_stemmed\", \"HS2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>squash racket</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>badminton racket</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     long_no_stopwords_stemmed HS2 pred\n",
       "364   squash racket             95  29 \n",
       "3540  badminton racket          95  29 "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_no_stopwords_stemmed\", \"HS2\", \"pred\"]\n",
    "CODE = \"29\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "cond3 = (test_reset[cols[0]].str.contains(\"racket\"))\n",
    "test_reset[cond1 & cond2 & cond3][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>racquetbal racket</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     long_no_stopwords_stemmed HS2 pred\n",
       "5425  racquetbal racket         95  95 "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reset[test_reset[cols[0]].str.contains(\"racquet\")][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this time, we did correctly predict the racquetball category! But, in aggregate, we appear to be doing worse, and still don't get the 'badminton' or 'squash' categories correct.\n",
    "\n",
    "We'll come back to TF-IDF, but let's try something that frequently helps bag-of-words models: we'll include _bigrams_ instead of unigrams. Frequently, in the English language, pairs of words -- and their order -- have meaning. While it may not help in a situation like the \"racquetball racket\" issue, it may help in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initially, we have 28469 records\n",
      "after deduping, we have 22372 records\n",
      "after removing <3 record categories, there are 22370 records\n",
      "training set has 16777 records -- 74.99776486365668 percent -- and test set has 5593 records\n",
      "in-sample accuracy:  0.987184836383\n",
      "test set accuracy:  0.923475773288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>squash racket</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>racquetbal racket</td>\n",
       "      <td>95</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     long_no_stopwords_stemmed HS2 pred\n",
       "364   squash racket             95  29 \n",
       "5425  racquetbal racket         95  29 "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = make_test_train(df, \"long_words_only\", \"HS2\")\n",
    "clf, vec = make_model(train, CountVectorizer(ngram_range=(1, 2)), \"long_words_only\", \"HS2\")\n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_words_only\", \"HS2\")\n",
    "\n",
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_no_stopwords_stemmed\", \"HS2\", \"pred\"]\n",
    "CODE = \"29\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "cond3 = (test_reset[cols[0]].str.contains(\"racket\"))\n",
    "test_reset[cond1 & cond2 & cond3][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've bumped our performance up about a percentage from our previous best, so this is worth keeping around.\n",
    "\n",
    "This still doesn't solve our issue of \"racquetball racket.\" What's going on there? Something else that frequently helps models like these is _subword information_. Now, from each word, we're going to create features for all subwords of ranges 2-6 of that word. As an example, the subwords of length 3 for \"racquetball\" would be\n",
    "- rac\n",
    "- acq\n",
    "- que\n",
    "- uet\n",
    "- etb\n",
    "- bal\n",
    "- all (where a special character differentiates the word \"all\" from the character sequence a-l-l)\n",
    "\n",
    "Perhaps \"rac\" and \"bal\" will be enough to cue the model that these records should be in chapter 95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initially, we have 28469 records\n",
      "after deduping, we have 22372 records\n",
      "after removing <3 record categories, there are 22370 records\n",
      "training set has 16777 records -- 74.99776486365668 percent -- and test set has 5593 records\n",
      "in-sample accuracy:  0.999284735054\n",
      "test set accuracy:  0.934024673699\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [long_no_stopwords_stemmed, HS2, pred]\n",
       "Index: []"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "fu = FeatureUnion([('word_counts', CountVectorizer()), \n",
    "                   ('char_counts', CountVectorizer(analyzer='char', ngram_range=(2, 6)))], n_jobs=2)\n",
    "train, test = make_test_train(df, \"long_words_only\", \"HS2\")\n",
    "clf, vec = make_model(train, fu, \"long_words_only\", \"HS2\")\n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_words_only\", \"HS2\")\n",
    "\n",
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_no_stopwords_stemmed\", \"HS2\", \"pred\"]\n",
    "CODE = \"29\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "cond3 = (test_reset[cols[0]].str.contains(\"racket\"))\n",
    "test_reset[cond1 & cond2 & cond3][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! We've fixed that particular issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         01       0.96      1.00      0.98        22\n",
      "         02       0.98      1.00      0.99        53\n",
      "         03       0.97      0.98      0.98       158\n",
      "         04       0.86      0.99      0.92        74\n",
      "         05       1.00      0.50      0.67        12\n",
      "         06       0.75      0.80      0.77        15\n",
      "         07       0.94      0.98      0.96        85\n",
      "         08       0.97      1.00      0.98        57\n",
      "         09       0.94      0.77      0.85        22\n",
      "         10       0.83      0.79      0.81        19\n",
      "         11       1.00      0.86      0.92        14\n",
      "         12       0.91      0.95      0.93        42\n",
      "         13       0.50      0.14      0.22         7\n",
      "         14       0.50      0.25      0.33         4\n",
      "         15       1.00      0.97      0.98        30\n",
      "         16       0.96      0.91      0.94        56\n",
      "         17       0.92      0.88      0.90        26\n",
      "         18       1.00      0.83      0.90        23\n",
      "         19       0.76      0.87      0.81        30\n",
      "         20       0.96      0.95      0.96        79\n",
      "         21       0.80      0.71      0.75        34\n",
      "         22       0.93      0.79      0.85        33\n",
      "         23       0.93      0.82      0.87        17\n",
      "         24       1.00      1.00      1.00        57\n",
      "         25       0.58      0.76      0.66        29\n",
      "         26       0.91      0.97      0.94        30\n",
      "         27       0.70      0.80      0.74        40\n",
      "         28       0.91      0.82      0.87        90\n",
      "         29       0.93      0.94      0.94       330\n",
      "         30       0.80      0.71      0.75        28\n",
      "         31       0.86      0.75      0.80         8\n",
      "         32       0.95      0.81      0.87        47\n",
      "         33       1.00      0.81      0.89        21\n",
      "         34       0.92      0.79      0.85        14\n",
      "         35       0.70      0.78      0.74         9\n",
      "         36       0.67      0.40      0.50         5\n",
      "         37       1.00      0.89      0.94        18\n",
      "         38       0.76      0.73      0.75        56\n",
      "         39       0.78      0.89      0.83        89\n",
      "         40       0.93      0.90      0.91        58\n",
      "         41       0.96      1.00      0.98        51\n",
      "         42       1.00      0.80      0.89        35\n",
      "         43       1.00      1.00      1.00        11\n",
      "         44       0.97      0.98      0.98       142\n",
      "         45       0.83      0.83      0.83         6\n",
      "         46       0.82      1.00      0.90        14\n",
      "         47       0.83      0.71      0.77         7\n",
      "         48       0.95      0.99      0.97        91\n",
      "         49       1.00      0.64      0.78        14\n",
      "         50       1.00      1.00      1.00         9\n",
      "         51       0.97      1.00      0.99        37\n",
      "         52       0.97      0.99      0.98       157\n",
      "         53       1.00      0.82      0.90        17\n",
      "         54       0.96      0.99      0.98        81\n",
      "         55       0.99      0.98      0.99       118\n",
      "         56       1.00      1.00      1.00        25\n",
      "         57       1.00      0.96      0.98        23\n",
      "         58       0.94      0.97      0.96        34\n",
      "         59       0.95      0.91      0.93        22\n",
      "         60       1.00      0.97      0.98        33\n",
      "         61       1.00      0.99      1.00       248\n",
      "         62       0.99      1.00      0.99       346\n",
      "         63       0.96      0.93      0.94        69\n",
      "         64       0.98      1.00      0.99       109\n",
      "         65       0.95      1.00      0.97        18\n",
      "         66       0.33      0.50      0.40         2\n",
      "         67       0.80      1.00      0.89         4\n",
      "         68       0.70      0.72      0.71        29\n",
      "         69       0.97      0.86      0.91        36\n",
      "         70       0.99      0.97      0.98        68\n",
      "         71       0.95      0.95      0.95        41\n",
      "         72       0.99      0.98      0.98       165\n",
      "         73       0.94      0.98      0.96       169\n",
      "         74       0.91      0.95      0.93        44\n",
      "         75       0.90      1.00      0.95         9\n",
      "         76       0.92      0.94      0.93        36\n",
      "         78       0.67      0.67      0.67         3\n",
      "         79       1.00      1.00      1.00         4\n",
      "         80       1.00      0.25      0.40         4\n",
      "         81       0.95      0.95      0.95        20\n",
      "         82       0.80      0.86      0.83        59\n",
      "         83       0.95      0.72      0.82        25\n",
      "         84       0.94      0.95      0.95       461\n",
      "         85       0.88      0.96      0.92       269\n",
      "         86       1.00      0.67      0.80         9\n",
      "         87       0.93      0.94      0.94       107\n",
      "         88       0.80      0.80      0.80        15\n",
      "         89       0.60      0.55      0.57        11\n",
      "         90       0.94      0.91      0.92       128\n",
      "         91       1.00      1.00      1.00       105\n",
      "         92       1.00      0.74      0.85        19\n",
      "         93       0.88      0.75      0.81        20\n",
      "         94       0.97      0.95      0.96        66\n",
      "         95       0.86      0.73      0.79        33\n",
      "         96       0.84      0.78      0.81        46\n",
      "         97       0.75      0.60      0.67         5\n",
      "         98       0.77      0.87      0.82        23\n",
      "\n",
      "avg / total       0.93      0.93      0.93      5593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's becoming harder to visually spot the worst performing classes. (There are ways to do this more easily: \"Bayesian Smoothing\").\n",
    "\n",
    "With 89 records in the test set and .83 f-score, chapter 39 \"plastics articles\" is doing poorly. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_words_only</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>imitation gemstones</td>\n",
       "      <td>39</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>cases bags and containers other of materials or coverings nesoi</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>waterbed mattresses and liners and parts of the foregoing</td>\n",
       "      <td>39</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>dynamite other high explosives put up in cartridges sticks or other forms suitable for blasting</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>polyvinyl chloride not mixed with any other substances</td>\n",
       "      <td>39</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>rattans in the rough 4 meters or more in length used primarily for plaiting</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>styrene butadiene rubber produced by emulsion polymerization e sbr in bales containing 50 or less styrene by wght of the dry polymer</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>ribbons measuring lt 30mm in width put up in plastic metal cartridges whether nt contn spools used in typewriters automatic data process other mach</td>\n",
       "      <td>96</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>signalling flares rain rockets fog signals and other pyrotechnic articles nesoi</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>firearms and similar devices which operate by the firing of an explosive charge nesoi</td>\n",
       "      <td>93</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>ultrasonic cleaning devices</td>\n",
       "      <td>84</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>animal sheds of plastic prefabricated buildings</td>\n",
       "      <td>94</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>indian mackrls seerfishes jacks crevalles silver pomfrets pacific saury scads capelin kawakawa bonitos marlins sailfishes spearfish fresh chilled</td>\n",
       "      <td>03</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>lamps parts of plastics</td>\n",
       "      <td>94</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>master batches of poly nitrilomethanetetraarylnitrilo 2 4 6 tris 1 methylethyl 1 3 phenylene 2 6 bis 1 methyl ethyl phenyl w 2 6 bis 1 methy</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>nets for gymnastics athletics other sports or outdoor games nesoi</td>\n",
       "      <td>95</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>monofilament cross sec dimen exceeds 1mm</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>melamine resins</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>siliceous fossil meals such as kieselguhr tripolite and diatomite similar siliceous earths of an apparent specific gravity lt 1</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>chemical derivatives of natural rubber</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>pelletized screenings clearings of other cereal grains nesoi</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>other medicaments primarily affecting the central nervous system not elsewhere specified or included</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>oils other products of coal tar distillation similar products in which the wt of the aromatic exceeds that of the nonaromatic constituents nesoi</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>salts of sulfated polyethers</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>o rings</td>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>pacifiers</td>\n",
       "      <td>39</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>other natural gum resins and gum resins nesoi</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>artificial christmas trees of plastic</td>\n",
       "      <td>95</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>polypropylene</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>casing for bicycle derailleur cables and casing for cable or inner wire for caliper and cantilever bakes whether or not cut to length</td>\n",
       "      <td>39</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>rattans in the rough 3 9 meters or less in length or cut transversely into sections used primarily for plaiting</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>styrene butadiene styrene block copolymers produced by solution polymerization sbs thermoplastic elastomers in granules crumbs or powders</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          long_words_only  \\\n",
       "126   imitation gemstones                                                                                                                                   \n",
       "158   cases bags and containers other of materials or coverings nesoi                                                                                       \n",
       "234   waterbed mattresses and liners and parts of the foregoing                                                                                             \n",
       "360   dynamite other high explosives put up in cartridges sticks or other forms suitable for blasting                                                       \n",
       "683   polyvinyl chloride not mixed with any other substances                                                                                                \n",
       "809   rattans in the rough 4 meters or more in length used primarily for plaiting                                                                           \n",
       "876   styrene butadiene rubber produced by emulsion polymerization e sbr in bales containing 50 or less styrene by wght of the dry polymer                  \n",
       "1124  ribbons measuring lt 30mm in width put up in plastic metal cartridges whether nt contn spools used in typewriters automatic data process other mach   \n",
       "1225  signalling flares rain rockets fog signals and other pyrotechnic articles nesoi                                                                       \n",
       "1336  firearms and similar devices which operate by the firing of an explosive charge nesoi                                                                 \n",
       "1536  ultrasonic cleaning devices                                                                                                                           \n",
       "1978  animal sheds of plastic prefabricated buildings                                                                                                       \n",
       "2186  indian mackrls seerfishes jacks crevalles silver pomfrets pacific saury scads capelin kawakawa bonitos marlins sailfishes spearfish fresh chilled     \n",
       "2204  lamps parts of plastics                                                                                                                               \n",
       "2356  master batches of poly nitrilomethanetetraarylnitrilo 2 4 6 tris 1 methylethyl 1 3 phenylene 2 6 bis 1 methyl ethyl phenyl w 2 6 bis 1 methy          \n",
       "2778  nets for gymnastics athletics other sports or outdoor games nesoi                                                                                     \n",
       "2786  monofilament cross sec dimen exceeds 1mm                                                                                                              \n",
       "3487  melamine resins                                                                                                                                       \n",
       "3624  siliceous fossil meals such as kieselguhr tripolite and diatomite similar siliceous earths of an apparent specific gravity lt 1                       \n",
       "3630  chemical derivatives of natural rubber                                                                                                                \n",
       "3816  pelletized screenings clearings of other cereal grains nesoi                                                                                          \n",
       "3845  other medicaments primarily affecting the central nervous system not elsewhere specified or included                                                  \n",
       "3850  oils other products of coal tar distillation similar products in which the wt of the aromatic exceeds that of the nonaromatic constituents nesoi      \n",
       "3882  salts of sulfated polyethers                                                                                                                          \n",
       "3995  o rings                                                                                                                                               \n",
       "4073  pacifiers                                                                                                                                             \n",
       "4142  other natural gum resins and gum resins nesoi                                                                                                         \n",
       "4479  artificial christmas trees of plastic                                                                                                                 \n",
       "4667  polypropylene                                                                                                                                         \n",
       "4873  casing for bicycle derailleur cables and casing for cable or inner wire for caliper and cantilever bakes whether or not cut to length                 \n",
       "5273  rattans in the rough 3 9 meters or less in length or cut transversely into sections used primarily for plaiting                                       \n",
       "5303  styrene butadiene styrene block copolymers produced by solution polymerization sbs thermoplastic elastomers in granules crumbs or powders             \n",
       "\n",
       "     HS2 pred  \n",
       "126   39  68   \n",
       "158   42  39   \n",
       "234   39  84   \n",
       "360   36  39   \n",
       "683   39  87   \n",
       "809   14  39   \n",
       "876   40  39   \n",
       "1124  96  39   \n",
       "1225  36  39   \n",
       "1336  93  39   \n",
       "1536  84  39   \n",
       "1978  94  39   \n",
       "2186  03  39   \n",
       "2204  94  39   \n",
       "2356  38  39   \n",
       "2778  95  39   \n",
       "2786  39  54   \n",
       "3487  39  35   \n",
       "3624  25  39   \n",
       "3630  39  40   \n",
       "3816  23  39   \n",
       "3845  30  39   \n",
       "3850  27  39   \n",
       "3882  34  39   \n",
       "3995  39  66   \n",
       "4073  39  84   \n",
       "4142  13  39   \n",
       "4479  95  39   \n",
       "4667  39  27   \n",
       "4873  39  73   \n",
       "5273  14  39   \n",
       "5303  40  39   "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_words_only\", \"HS2\", \"pred\"]\n",
    "CODE = \"39\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "test_reset[cond1 & cond2][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initially, we have 28469 records\n",
      "after deduping, we have 22372 records\n",
      "after removing <3 record categories, there are 22370 records\n",
      "training set has 16777 records -- 74.99776486365668 percent -- and test set has 5593 records\n",
      "in-sample accuracy:  0.996960123979\n",
      "test set accuracy:  0.932773109244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [long_no_stopwords_stemmed, HS2, pred]\n",
       "Index: []"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FirstTwoVectorizer(CountVectorizer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        dudes = X.str.split().str[:2].apply(\" \".join)\n",
    "        super().fit(dudes, y)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "fu = FeatureUnion([('word_counts', CountVectorizer()), \n",
    "                   ('char_counts', CountVectorizer(analyzer='char', ngram_range=(2, 6))),\n",
    "                   ('first_two', FirstTwoVectorizer())], n_jobs=2, transformer_weights={'first_two': 2, 'word_counts': 1, 'char_counts': 1})\n",
    "train, test = make_test_train(df, \"long_no_stopwords\", \"HS2\")\n",
    "clf, vec = make_model(train, fu, \"long_no_stopwords\", \"HS2\")\n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_no_stopwords\", \"HS2\")\n",
    "\n",
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_no_stopwords_stemmed\", \"HS2\", \"pred\"]\n",
    "CODE = \"29\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "cond3 = (test_reset[cols[0]].str.contains(\"racket\"))\n",
    "test_reset[cond1 & cond2 & cond3][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try something else. We've been using logistic regression up until now. One of the nice things about SGD is that it's also easy to implement a performant _Linear Support Vector Machine_ (SVM), simply by changing the loss function that we are performing SGD to optimize.\n",
    "\n",
    "Instead of 'log' loss, SGD uses 'hinge' loss. In the `make_model` function above, I included a parameter to modify the loss for ease-of-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initially, we have 28469 records\n",
      "after deduping, we have 22372 records\n",
      "after removing <3 record categories, there are 22370 records\n",
      "training set has 16777 records -- 74.99776486365668 percent -- and test set has 5593 records\n",
      "in-sample accuracy:  0.997675388925\n",
      "test set accuracy:  0.932415519399\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "      <th>HS2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [long_no_stopwords_stemmed, HS2, pred]\n",
       "Index: []"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fu = FeatureUnion([('word_counts', CountVectorizer()), \n",
    "                   ('char_counts', CountVectorizer(analyzer='char', ngram_range=(2, 6)))], n_jobs=2)\n",
    "train, test = make_test_train(df, \"long_words_only\", \"HS2\")\n",
    "clf, vec = make_model(train, fu, \"long_words_only\", \"HS2\", loss='hinge')\n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_words_only\", \"HS2\")\n",
    "\n",
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_no_stopwords_stemmed\", \"HS2\", \"pred\"]\n",
    "CODE = \"29\"\n",
    "cond1 = (test_reset[\"HS2\"] == CODE) | (test_reset[\"pred\"] == CODE)\n",
    "cond2 = (test_reset[\"HS2\"] != test_reset[\"pred\"])\n",
    "cond3 = (test_reset[cols[0]].str.contains(\"racket\"))\n",
    "test_reset[cond1 & cond2 & cond3][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>asses</th>\n",
       "      <th>breeding</th>\n",
       "      <th>except</th>\n",
       "      <th>female</th>\n",
       "      <th>for</th>\n",
       "      <th>horses</th>\n",
       "      <th>immediate</th>\n",
       "      <th>imported</th>\n",
       "      <th>live</th>\n",
       "      <th>male</th>\n",
       "      <th>nesoi</th>\n",
       "      <th>purebred</th>\n",
       "      <th>slaughter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_words_only</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>horses and asses purebred breeding male live</th>\n",
       "      <td>0.428751</td>\n",
       "      <td>0.355902</td>\n",
       "      <td>0.355902</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.299396</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.253227</td>\n",
       "      <td>0.531425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355902</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horses and asses purebred breeding female live</th>\n",
       "      <td>0.428751</td>\n",
       "      <td>0.355902</td>\n",
       "      <td>0.355902</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.531425</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.299396</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.253227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355902</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horses imported for immediate slaughter live except purebred breeding</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263873</td>\n",
       "      <td>0.39401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.39401</td>\n",
       "      <td>0.221978</td>\n",
       "      <td>0.39401</td>\n",
       "      <td>0.39401</td>\n",
       "      <td>0.187748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263873</td>\n",
       "      <td>0.39401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horses live nesoi</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.453331</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.383424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asses live</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.814802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            and  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.428751   \n",
       "horses and asses purebred breeding female live                         0.428751   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.000000   \n",
       "horses live nesoi                                                      0.000000   \n",
       "asses live                                                             0.000000   \n",
       "\n",
       "                                                                          asses  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.355902   \n",
       "horses and asses purebred breeding female live                         0.355902   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.000000   \n",
       "horses live nesoi                                                      0.000000   \n",
       "asses live                                                             0.814802   \n",
       "\n",
       "                                                                       breeding  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.355902   \n",
       "horses and asses purebred breeding female live                         0.355902   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.263873   \n",
       "horses live nesoi                                                      0.000000   \n",
       "asses live                                                             0.000000   \n",
       "\n",
       "                                                                        except  \\\n",
       "long_words_only                                                                  \n",
       "horses and asses purebred breeding male live                           0.00000   \n",
       "horses and asses purebred breeding female live                         0.00000   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.39401   \n",
       "horses live nesoi                                                      0.00000   \n",
       "asses live                                                             0.00000   \n",
       "\n",
       "                                                                         female  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.000000   \n",
       "horses and asses purebred breeding female live                         0.531425   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.000000   \n",
       "horses live nesoi                                                      0.000000   \n",
       "asses live                                                             0.000000   \n",
       "\n",
       "                                                                           for  \\\n",
       "long_words_only                                                                  \n",
       "horses and asses purebred breeding male live                           0.00000   \n",
       "horses and asses purebred breeding female live                         0.00000   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.39401   \n",
       "horses live nesoi                                                      0.00000   \n",
       "asses live                                                             0.00000   \n",
       "\n",
       "                                                                         horses  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.299396   \n",
       "horses and asses purebred breeding female live                         0.299396   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.221978   \n",
       "horses live nesoi                                                      0.453331   \n",
       "asses live                                                             0.000000   \n",
       "\n",
       "                                                                       immediate  \\\n",
       "long_words_only                                                                    \n",
       "horses and asses purebred breeding male live                           0.00000     \n",
       "horses and asses purebred breeding female live                         0.00000     \n",
       "horses imported for immediate slaughter live except purebred breeding  0.39401     \n",
       "horses live nesoi                                                      0.00000     \n",
       "asses live                                                             0.00000     \n",
       "\n",
       "                                                                       imported  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.00000    \n",
       "horses and asses purebred breeding female live                         0.00000    \n",
       "horses imported for immediate slaughter live except purebred breeding  0.39401    \n",
       "horses live nesoi                                                      0.00000    \n",
       "asses live                                                             0.00000    \n",
       "\n",
       "                                                                           live  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.253227   \n",
       "horses and asses purebred breeding female live                         0.253227   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.187748   \n",
       "horses live nesoi                                                      0.383424   \n",
       "asses live                                                             0.579739   \n",
       "\n",
       "                                                                           male  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.531425   \n",
       "horses and asses purebred breeding female live                         0.000000   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.000000   \n",
       "horses live nesoi                                                      0.000000   \n",
       "asses live                                                             0.000000   \n",
       "\n",
       "                                                                          nesoi  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.000000   \n",
       "horses and asses purebred breeding female live                         0.000000   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.000000   \n",
       "horses live nesoi                                                      0.804659   \n",
       "asses live                                                             0.000000   \n",
       "\n",
       "                                                                       purebred  \\\n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.355902   \n",
       "horses and asses purebred breeding female live                         0.355902   \n",
       "horses imported for immediate slaughter live except purebred breeding  0.263873   \n",
       "horses live nesoi                                                      0.000000   \n",
       "asses live                                                             0.000000   \n",
       "\n",
       "                                                                       slaughter  \n",
       "long_words_only                                                                   \n",
       "horses and asses purebred breeding male live                           0.00000    \n",
       "horses and asses purebred breeding female live                         0.00000    \n",
       "horses imported for immediate slaughter live except purebred breeding  0.39401    \n",
       "horses live nesoi                                                      0.00000    \n",
       "asses live                                                             0.00000    "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "# this will actually convert our first few descriptions into vectors\n",
    "tfd = vec.fit_transform(first_few_only['long_words_only'])\n",
    "# by default, it's a sparse matrix\n",
    "tfd.toarray()\n",
    "# don't worry about this, it's for pedagogical purposes\n",
    "columns = [x[0] for x in sorted(list(vec.vocabulary_.items()), key=lambda x: x[1])]\n",
    "pd.DataFrame(tfd.toarray(), columns=columns, index=first_few_only['long_words_only'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, without further ado, let's try a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after deduping, we have 22372 records\n",
      "after removing <2 record categories, there are 22248 records\n",
      "training set has 16686 records -- 75.0 percent -- and test set has 5562 records\n",
      "in-sample accuracy:  0.76585161213\n",
      "test set accuracy:  0.686983099604\n"
     ]
    }
   ],
   "source": [
    "train, test = make_test_train(df, \"long_words_only\", \"HS4\")\n",
    "clf, vec = make_model(train, TfidfVectorizer(binary=True), \"long_words_only\", \"HS4\")\n",
    "y_test_true, y_test_pred = evaluate_model(clf, vec, train, test, \"long_words_only\", \"HS4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_words_only</th>\n",
       "      <th>HS4</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>pears otherwise prepared or preserved whether or not containing sweetening or spirit nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>citrus fruit pulp prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>snails other than sea snails prepared or preserved</td>\n",
       "      <td>1605</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>crabs prepared or preserved nesoi</td>\n",
       "      <td>1605</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>cockles and arkshells prepared or preserved</td>\n",
       "      <td>1605</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>yellow potatoes solano except french fries prepared or preserved otherwise than by vinegar frozen</td>\n",
       "      <td>2004</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>vegetables fruit nuts fruit peel and other parts of plants preserved by sugar drained glace or crystallized</td>\n",
       "      <td>2006</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>sea cucumbers prepared or preserved nesoi</td>\n",
       "      <td>1605</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>fruit nuts and other edible parts of plants nesoi prepared or preserved by vinegar or acetic acid</td>\n",
       "      <td>2001</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>clementines wilkings and similar citrus hybrids prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>fruit and other edible parts of plants nesoi otherwise prepared or preserved whether or not containing sweetening or spirit nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>prepared foods obtained by the swelling or roasting of cereals or cereal products not containing cane and or beet sugar</td>\n",
       "      <td>1904</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>lactams nesoi</td>\n",
       "      <td>2933</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>antiallergenic preperations nesoi</td>\n",
       "      <td>3002</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>anchovies prepared or preserved nesoi in immediate containers weighing with their contents 6 8 kg or less each</td>\n",
       "      <td>1604</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>grapes prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>tapioca and substitutes prepared from starch nesoi in the form of flakes grains pearls siftings or in similar forms</td>\n",
       "      <td>1903</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>fruit mixtures nesoi prepared nesoi packed in a liquid medium in airtight containers</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>aquatic invertebrates prepared or preserved nesoi</td>\n",
       "      <td>1605</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>watermelon seeds prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>nectarines prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>oranges prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>structures parts of structures and articles prepared for use in structures nesoi of iron or steel</td>\n",
       "      <td>7308</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>nectarines prepared nesoi in containers holding less than 1 4 kg each</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>apricot pulp prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>macadamia nuts prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>cucumbers including gherkins prepared or preserved by vinegar or acetic acid</td>\n",
       "      <td>2001</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>mixtures of fruit nuts edible parts of plants prepared nesoi in airtight containers no apricots citrus fruits peaches or pears</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>trees shrubs and bushes grafted or not of kinds which bears edible fruit or nuts</td>\n",
       "      <td>0602</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>mixtures of pork and beef prepared or preserved</td>\n",
       "      <td>1602</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>red raspberries prepared or preserved</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>blueberries except canned wild blueberries prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>mixtures of fruit nuts and other edible parts of plants nesoi otherwise prepared or preserved whether containing sweetening matter or spirit</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>cherries tart varieties prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>grapefruit prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>clams prepared or preserved</td>\n",
       "      <td>1605</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>birds eggs in shell preserved or cooked</td>\n",
       "      <td>0407</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>banana pulp prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>lemons citrus limon citrus limonum prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>artificial waxes and prepared waxes nesoi</td>\n",
       "      <td>3404</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>microtomes nesoi</td>\n",
       "      <td>9027</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>prepared foods obtained by the swelling or roasting of cereals or cereal products containing cane and or beet sugar</td>\n",
       "      <td>1904</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>peanuts ground nuts prepared or preserved nesoi described in general note 15 of the tariff schedule and entered pursuant to its provisions</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5086</th>\n",
       "      <td>microphones nesoi</td>\n",
       "      <td>8518</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>peanuts ground nuts prepared or preserved nesoi described in additional u s note 2 to chapter 12 and entered pursuant to its provisions</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>kumquats prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>avocados prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>cashews prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>mixtures of nuts peanuts or other seeds prepared or preserved nesoi</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>typewriter or similar ribbons nesoi inked or otherwise prepared for giving impressions whether or not on spools or in cartridges</td>\n",
       "      <td>9612</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                   long_words_only  \\\n",
       "506   pears otherwise prepared or preserved whether or not containing sweetening or spirit nesoi                                                     \n",
       "684   citrus fruit pulp prepared or preserved nesoi                                                                                                  \n",
       "854   snails other than sea snails prepared or preserved                                                                                             \n",
       "949   crabs prepared or preserved nesoi                                                                                                              \n",
       "969   cockles and arkshells prepared or preserved                                                                                                    \n",
       "1083  yellow potatoes solano except french fries prepared or preserved otherwise than by vinegar frozen                                              \n",
       "1164  vegetables fruit nuts fruit peel and other parts of plants preserved by sugar drained glace or crystallized                                    \n",
       "1259  sea cucumbers prepared or preserved nesoi                                                                                                      \n",
       "1427  fruit nuts and other edible parts of plants nesoi prepared or preserved by vinegar or acetic acid                                              \n",
       "1560  clementines wilkings and similar citrus hybrids prepared or preserved nesoi                                                                    \n",
       "1607  fruit and other edible parts of plants nesoi otherwise prepared or preserved whether or not containing sweetening or spirit nesoi              \n",
       "1611  prepared foods obtained by the swelling or roasting of cereals or cereal products not containing cane and or beet sugar                        \n",
       "1615  lactams nesoi                                                                                                                                  \n",
       "1726  antiallergenic preperations nesoi                                                                                                              \n",
       "1748  anchovies prepared or preserved nesoi in immediate containers weighing with their contents 6 8 kg or less each                                 \n",
       "1977  grapes prepared or preserved nesoi                                                                                                             \n",
       "2150  tapioca and substitutes prepared from starch nesoi in the form of flakes grains pearls siftings or in similar forms                            \n",
       "2201  fruit mixtures nesoi prepared nesoi packed in a liquid medium in airtight containers                                                           \n",
       "2392  aquatic invertebrates prepared or preserved nesoi                                                                                              \n",
       "2422  watermelon seeds prepared or preserved nesoi                                                                                                   \n",
       "2451  nectarines prepared or preserved nesoi                                                                                                         \n",
       "2525  oranges prepared or preserved nesoi                                                                                                            \n",
       "2780  structures parts of structures and articles prepared for use in structures nesoi of iron or steel                                              \n",
       "3446  nectarines prepared nesoi in containers holding less than 1 4 kg each                                                                          \n",
       "3526  apricot pulp prepared or preserved nesoi                                                                                                       \n",
       "3588  macadamia nuts prepared or preserved nesoi                                                                                                     \n",
       "3696  cucumbers including gherkins prepared or preserved by vinegar or acetic acid                                                                   \n",
       "3962  mixtures of fruit nuts edible parts of plants prepared nesoi in airtight containers no apricots citrus fruits peaches or pears                 \n",
       "4026  trees shrubs and bushes grafted or not of kinds which bears edible fruit or nuts                                                               \n",
       "4054  mixtures of pork and beef prepared or preserved                                                                                                \n",
       "4103  red raspberries prepared or preserved                                                                                                          \n",
       "4146  blueberries except canned wild blueberries prepared or preserved nesoi                                                                         \n",
       "4228  mixtures of fruit nuts and other edible parts of plants nesoi otherwise prepared or preserved whether containing sweetening matter or spirit   \n",
       "4316  cherries tart varieties prepared or preserved nesoi                                                                                            \n",
       "4459  grapefruit prepared or preserved nesoi                                                                                                         \n",
       "4521  clams prepared or preserved                                                                                                                    \n",
       "4741  birds eggs in shell preserved or cooked                                                                                                        \n",
       "4795  banana pulp prepared or preserved nesoi                                                                                                        \n",
       "4973  lemons citrus limon citrus limonum prepared or preserved nesoi                                                                                 \n",
       "5007  artificial waxes and prepared waxes nesoi                                                                                                      \n",
       "5041  microtomes nesoi                                                                                                                               \n",
       "5068  prepared foods obtained by the swelling or roasting of cereals or cereal products containing cane and or beet sugar                            \n",
       "5084  peanuts ground nuts prepared or preserved nesoi described in general note 15 of the tariff schedule and entered pursuant to its provisions     \n",
       "5086  microphones nesoi                                                                                                                              \n",
       "5118  peanuts ground nuts prepared or preserved nesoi described in additional u s note 2 to chapter 12 and entered pursuant to its provisions        \n",
       "5203  kumquats prepared or preserved nesoi                                                                                                           \n",
       "5280  avocados prepared or preserved nesoi                                                                                                           \n",
       "5288  cashews prepared or preserved nesoi                                                                                                            \n",
       "5389  mixtures of nuts peanuts or other seeds prepared or preserved nesoi                                                                            \n",
       "5511  typewriter or similar ribbons nesoi inked or otherwise prepared for giving impressions whether or not on spools or in cartridges               \n",
       "\n",
       "       HS4  pred  \n",
       "506   2008  2008  \n",
       "684   2008  2008  \n",
       "854   1605  2008  \n",
       "949   1605  2008  \n",
       "969   1605  2008  \n",
       "1083  2004  2008  \n",
       "1164  2006  2008  \n",
       "1259  1605  2008  \n",
       "1427  2001  2008  \n",
       "1560  2008  2008  \n",
       "1607  2008  2008  \n",
       "1611  1904  2008  \n",
       "1615  2933  2008  \n",
       "1726  3002  2008  \n",
       "1748  1604  2008  \n",
       "1977  2008  2008  \n",
       "2150  1903  2008  \n",
       "2201  2008  2008  \n",
       "2392  1605  2008  \n",
       "2422  2008  2008  \n",
       "2451  2008  2008  \n",
       "2525  2008  2008  \n",
       "2780  7308  2008  \n",
       "3446  2008  2008  \n",
       "3526  2008  2008  \n",
       "3588  2008  2008  \n",
       "3696  2001  2008  \n",
       "3962  2008  2008  \n",
       "4026  0602  2008  \n",
       "4054  1602  2008  \n",
       "4103  2008  2008  \n",
       "4146  2008  2008  \n",
       "4228  2008  2008  \n",
       "4316  2008  2008  \n",
       "4459  2008  2008  \n",
       "4521  1605  2008  \n",
       "4741  0407  2008  \n",
       "4795  2008  2008  \n",
       "4973  2008  2008  \n",
       "5007  3404  2008  \n",
       "5041  9027  2008  \n",
       "5068  1904  2008  \n",
       "5084  2008  2008  \n",
       "5086  8518  2008  \n",
       "5118  2008  2008  \n",
       "5203  2008  2008  \n",
       "5280  2008  2008  \n",
       "5288  2008  2008  \n",
       "5389  2008  2008  \n",
       "5511  9612  2008  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reset = test.reset_index()\n",
    "test_reset[\"pred\"] = y_test_pred\n",
    "\n",
    "cols = [\"long_words_only\", \"HS4\", \"pred\"]\n",
    "CODE = \"2008\"\n",
    "test_reset[(test_reset[\"HS4\"] == CODE) | (test_reset[\"pred\"] == CODE)][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blah blah NlP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS10</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>long_words_only</th>\n",
       "      <th>HS2</th>\n",
       "      <th>HS4</th>\n",
       "      <th>HS6</th>\n",
       "      <th>long_no_stopwords</th>\n",
       "      <th>long_no_stopwords_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101210010</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE</td>\n",
       "      <td>horses and asses purebred breeding male live</td>\n",
       "      <td>01</td>\n",
       "      <td>0101</td>\n",
       "      <td>010121</td>\n",
       "      <td>horses asses purebred breeding male live</td>\n",
       "      <td>horses asses purebred breeding male l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101210020</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE</td>\n",
       "      <td>horses and asses purebred breeding female live</td>\n",
       "      <td>01</td>\n",
       "      <td>0101</td>\n",
       "      <td>010121</td>\n",
       "      <td>horses asses purebred breeding female live</td>\n",
       "      <td>horses asses purebred breeding female l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101290010</td>\n",
       "      <td>HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI</td>\n",
       "      <td>HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING</td>\n",
       "      <td>horses imported for immediate slaughter live except purebred breeding</td>\n",
       "      <td>01</td>\n",
       "      <td>0101</td>\n",
       "      <td>010129</td>\n",
       "      <td>horses imported immediate slaughter live except purebred breeding</td>\n",
       "      <td>horses imported immediate slaughter live except purebred breed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101290090</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "      <td>HORSES, LIVE, NESOI</td>\n",
       "      <td>horses live nesoi</td>\n",
       "      <td>01</td>\n",
       "      <td>0101</td>\n",
       "      <td>010129</td>\n",
       "      <td>horses live</td>\n",
       "      <td>horses l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101300000</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "      <td>ASSES, LIVE</td>\n",
       "      <td>asses live</td>\n",
       "      <td>01</td>\n",
       "      <td>0101</td>\n",
       "      <td>010130</td>\n",
       "      <td>asses live</td>\n",
       "      <td>asses l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HS10                                           short_desc  \\\n",
       "0  0101210010  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE       \n",
       "1  0101210020  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE     \n",
       "2  0101290010  HORSES, FOR IMMEDIATE SLAUGHTER, LIVE, NESOI          \n",
       "3  0101290090  HORSES, LIVE, NESOI                                   \n",
       "4  0101300000  ASSES, LIVE                                           \n",
       "\n",
       "                                                                                                                                                long_desc  \\\n",
       "0  HORSES AND ASSES, PUREBRED BREEDING, MALE, LIVE                                                                                                          \n",
       "1  HORSES AND ASSES, PUREBRED BREEDING, FEMALE, LIVE                                                                                                        \n",
       "2  HORSES, IMPORTED FOR IMMEDIATE SLAUGHTER, LIVE, EXCEPT PUREBRED BREEDING                                                                                 \n",
       "3  HORSES, LIVE, NESOI                                                                                                                                      \n",
       "4  ASSES, LIVE                                                                                                                                              \n",
       "\n",
       "                                                         long_words_only HS2  \\\n",
       "0  horses and asses purebred breeding male live                           01   \n",
       "1  horses and asses purebred breeding female live                         01   \n",
       "2  horses imported for immediate slaughter live except purebred breeding  01   \n",
       "3  horses live nesoi                                                      01   \n",
       "4  asses live                                                             01   \n",
       "\n",
       "    HS4     HS6  \\\n",
       "0  0101  010121   \n",
       "1  0101  010121   \n",
       "2  0101  010129   \n",
       "3  0101  010129   \n",
       "4  0101  010130   \n",
       "\n",
       "                                                   long_no_stopwords  \\\n",
       "0  horses asses purebred breeding male live                            \n",
       "1  horses asses purebred breeding female live                          \n",
       "2  horses imported immediate slaughter live except purebred breeding   \n",
       "3  horses live                                                         \n",
       "4  asses live                                                          \n",
       "\n",
       "                                        long_no_stopwords_stemmed  \n",
       "0  horses asses purebred breeding male l                           \n",
       "1  horses asses purebred breeding female l                         \n",
       "2  horses imported immediate slaughter live except purebred breed  \n",
       "3  horses l                                                        \n",
       "4  asses l                                                         "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after deduping, we have 21293 records\n",
      "after removing <2 record categories, there are 21293 records\n",
      "training set has 15969 records -- 74.99647771568121 percent -- and test set has 5324 records\n"
     ]
    }
   ],
   "source": [
    "deduped = df.drop_duplicates(subset=[\"long_no_stopwords\"])\n",
    "print(\"after deduping, we have\", len(deduped), \"records\")\n",
    "\n",
    "#now, let's remove any HS4 category with <2 records\n",
    "vcs = deduped[\"HS2\"].value_counts()\n",
    "to_include = vcs[vcs > 1].index\n",
    "final_dataset = deduped[deduped.HS2.isin(to_include)]\n",
    "print(\"after removing <2 record categories, there are\", len(final_dataset), \"records\")\n",
    "\n",
    "# the stratify is important -- \n",
    "# it's making sure that we have an instance of each category in both the train and test sets\n",
    "\n",
    "train, test = train_test_split(final_dataset, stratify=final_dataset[\"HS2\"])\n",
    "print(\"training set has\", len(train), \"records --\", 100 * len(train) / len(final_dataset), \n",
    "      \"percent -- and test set has\", len(test), \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.miniconda2/envs/new_gpd_3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial accuracy:  0.9256198347107438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(train[\"long_no_stopwords\"])\n",
    "y = train[\"HS2\"]\n",
    "\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "X_test = cv.transform(test[\"long_no_stopwords\"])\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_true = test[\"HS2\"]\n",
    "print(\"initial accuracy: \", (y_test_pred == y_test_true).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after deduping, we have 21254 records\n",
      "after removing <2 record categories, there are 21254 records\n",
      "training set has 15940 records -- 74.99764750164675 percent -- and test set has 5314 records\n"
     ]
    }
   ],
   "source": [
    "deduped = df.drop_duplicates(subset=[\"long_no_stopwords_stemmed\"])\n",
    "print(\"after deduping, we have\", len(deduped), \"records\")\n",
    "\n",
    "#now, let's remove any HS4 category with <2 records\n",
    "vcs = deduped[\"HS2\"].value_counts()\n",
    "to_include = vcs[vcs > 1].index\n",
    "final_dataset = deduped[deduped.HS2.isin(to_include)]\n",
    "print(\"after removing <2 record categories, there are\", len(final_dataset), \"records\")\n",
    "\n",
    "# the stratify is important -- \n",
    "# it's making sure that we have an instance of each category in both the train and test sets\n",
    "\n",
    "train, test = train_test_split(final_dataset, stratify=final_dataset[\"HS2\"])\n",
    "print(\"training set has\", len(train), \"records --\", 100 * len(train) / len(final_dataset), \n",
    "      \"percent -- and test set has\", len(test), \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.miniconda2/envs/new_gpd_3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial accuracy:  0.922092585622883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(train[\"long_no_stopwords_stemmed\"])\n",
    "y = train[\"HS2\"]\n",
    "\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "X_test = cv.transform(test[\"long_no_stopwords_stemmed\"])\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_true = test[\"HS2\"]\n",
    "print(\"initial accuracy: \", (y_test_pred == y_test_true).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/.miniconda2/envs/new_gpd_3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial accuracy:  0.9190816710575838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = TfidfVectorizer()\n",
    "X = cv.fit_transform(train[\"long_no_stopwords_stemmed\"])\n",
    "y = train[\"HS2\"]\n",
    "\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "X_test = cv.transform(test[\"long_no_stopwords_stemmed\"])\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_true = test[\"HS2\"]\n",
    "print(\"initial accuracy: \", (y_test_pred == y_test_true).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial accuracy:  0.8831388784343245\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = rf.predict(X_test)\n",
    "y_test_true = test[\"HS2\"]\n",
    "print(\"initial accuracy: \", (y_test_pred == y_test_true).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
